Lemma Theorem Corollary

=0 =0

The Power and Limitations of Static Binary Search Trees with Lazy Finger

Karim Douïeb

John Iacono

Stefan Langerman

Introduction

Static trees

A binary search tree is one of the most fundamental data structures in computer science. In response to a search operation, some binary trees perform changes in the data structure, while others do not. For example, the splay tree [\cite=DBLP:journals/jacm/SleatorT85] data structure performs a sequence of searches that moves the searched item to the root. Other binary search tree data structures do not change at all during a search, for example, red-black trees [\cite=DBLP:conf/focs/GuibasS78] and AVL trees [\cite=tree-adelson-62]. We will call BSTs that do not perform changes in the structure during searches to be static and call trees that perform changes BSTs with rotations. In this work we do not consider insertions and deletions, only searches, and thus can assume without loss of generality that all structures under consideration are storing the integers from 1 to n and that all searches are to these items.

We consider two variants of static BSTs: root finger and lazy finger. In the classic method, the root finger method, the first search proceeds from the root to the item being searched. In the second and subsequent searches, a root finger BST executes the searches in the same manner, always starting each search from the root. In contrast, here we consider lazy finger BSTs to be those which start each search at the destination of the previous search and move to the item being searched. In general, this movement involves going up to the least common ancestor (LCA) of the previous and current items being searched, and then moving down from the LCA to the current item being searched.

Notation and definitions

A static tree T is a fixed binary search tree containing n elements. No rotations are allowed. The data structure must process a sequence of searches, by moving a single pointer in the tree. Let r(T,i,j) be the time to move the pointer in the tree T from node i to j. If dT(i) represents the depth of node i, with the root defined as having depth zero, then

[formula]

The runtime to execute a sequence [formula] of searches on a tree T using the root finger method is

[formula]

and the runtime to execute the same sequence on a tree T using the lazy finger method is

[formula]

where x0 is defined to be the root of T, which is where the first search starts.

History of optimal static trees with root finger

For the root finger method, once the tree T is fixed, the cost of any single search in tree T depends only on the search and the tree, not on any of the search history. Thus, the optimal search tree for the root finger method is a function only of the frequency of the searches for each item. Let fX(a) denote the number of searches in X to a. Given fX, computing the optimal static BST with root finger has a long history. In 1971, Knuth gave a O(n2) dynamic programming solution that finds the optimum tree [\cite=DBLP:journals/acta/Knuth71]. More interestingly is the discovery of a connection between the runtime of the optimal tree and the entropy of the frequencies:

[formula]

.

Melhorn [\cite=DBLP:journals/acta/Mehlhorn75] showed that a simple greedy heuristic proposed by Knuth [\cite=DBLP:journals/acta/Knuth71] and shown to have a linear-time implementation by Fredman [\cite=DBLP:conf/stoc/Fredman75] produced a static tree where an average search took time [formula]. Furthermore, Melhorn demonstrated a lower bound of [formula] for an average search in an optimal static tree, and showed this bound was tight for infinitely many distributions. Thus, by 1975, it was established that the runtime for an average search in an optimal search tree with root finger was O(H(fX)), and that such a tree could easily be computed in linear time.

Our results

We wish to study the natural problem of what we have coined search with a lazy finger in a static tree, i.e. have each search start where the last one ended. We seek to characterize the optimal tree for this search strategy, and describe how to build it.

The lazy finger method is asymptotically clearly no worse then the root finger method; moving up to the LCA and back down is better than moving to the root and back down, which is exactly double the cost of the root finger method. But, in general, is the lazy finger method better? For the lazy finger method, the cost of a single search in a static tree depends only on the current search and the previous search--this puts lazy finger's runtime dependence on the search sequence between that of root finger and trees with rotations. Thus the optimal search tree for the lazy finger method only depends on the frequency of each search transition; let fX(a,b) be the number of searches in X to b where the previous search was to a. Given these pairwise frequencies (from which the frequencies fX(a) can easily be computed), is there a nice closed form for the runtime of the optimal BST with lazy finger? One natural runtime to consider is the conditional entropy:

[formula]

This is of interest as information theory gives this as an expected lower bound if the search sequence is derived from a Markov chain where n states represents searching each item.

While a runtime related to the conditional entropy is the best achievable by any algorithm parameterized solely on the pairwise frequencies, however, we will show in Lemma [\ref=l:conditionalentropysuck] that the conditional entropy is impossible to be asymptotically achieved for any BST, static or dynamic, within any o( log n) factor. Thus, for the root finger, the lower bound given by information theory is achievable, for lazy finger it is not related in any minimal way with the runtime of the optimal tree. In Section [\ref=s:multitree] we will present a simple static non-tree structure whose runtime is related to the conditional entropy.

This still leaves us with the question: is there a simple closed form for the runtime of the optimal BST with lazy finger? We answer this in the affirmative by showing an equivalence between the runtime of BSTs with lazy finger and something known as the weighted dynamic finger runtime. In the weighted dynamic finger runtime, if item i is given weight wi, then the time to execute search xi is

[formula]

Our main theorem is that the runtime of the best static tree with lazy finger, LF(X), is given by the weighted dynamic finger runtime bound with the best choice of weights:

[formula]

To prove this, we first state the result of Seidel and Aragon [\cite=DBLP:journals/algorithmica/SeidelA96] in Section [\ref=s:weightsgivetrees] of how to construct a tree with the weighted dynamic finger runtime given a set of weights. Then, in Section [\ref=s:trresgiveweights], we show how, given any static tree T, there exists weights such the runtime of T on a sequence using lazy finger can be lower bounded using the weighted dynamic finger runtime with these weights. These results are combined in Section [\ref=s:main] to give the main theorem.

While a nice closed-form formula for the runtime of splay trees is not known, there are several different bounds on their runtime: working set, static finger, dynamic finger, and static optimality [\cite=DBLP:journals/jacm/SleatorT85] [\cite=DBLP:journals/siamcomp/ColeMSS00] [\cite=DBLP:journals/siamcomp/Cole00]. One implication of our result is that the runtime of the optimal lazy finger tree is asymptotically as good as that of all of the aforementioned bounds with the exception of the working set bound (see Theorem [\ref=th:limit] for why the working set bound does not hold on a lazy finger static structure).

However, while these results have served to characterize the best runtime for the optimal BST, a concrete method is needed to compute the best tree given the pairwise frequencies. We present a dynamic programming solution in Section [\ref=s:dynprog]; this solution takes time O(n3) to compute the optimal tree for lazy finger, given a table of size n2 with the frequency of each pair of searches occurring adjacently. This method could be extended using the ideas of [\cite=DBLP:journals/ijcga/IaconoM12] into one which periodically rebuilds the static structure using the observed frequencies so far; the result would be an online structure that for sufficiently long search sequences achieves a runtime that is within a constant factor of the optimal tree without needing to be initialized with the pairwise frequencies.

Why static trees?

Static trees are less powerful than dynamic ones in terms of the classes of search sequence distributions that can be executed quickly, so why are we studying them? Here we list a few reasons:

Rotation-based trees have horrible cache performance. However, there are methods to map the nodes of a static tree to memory so as to have optimal performance in the disk-access model and cache-oblivious models of the memory hierarchy [\cite=DBLP:journals/ipl/Boas77] [\cite=DBLP:journals/corr/cs-DS-0410048] [\cite=DBLP:journals/jal/GilI99] [\cite=DBLP:conf/soda/ClarkM96]. One leading cache oblivious predecessor query data structure that supports insertion and deletion works by having a static tree and moves the data around in the fixed static tree in response to insertions and deletions and only periodically rebuilds the static structure [\cite=DBLP:journals/jal/BenderDIW04]--in such a structure an efficient static structure is the key to obtaining good performance even with insertions and deletions.

One should use the simplest structure with the least overhead that gets the job done. By completely categorizing the runtime of the optimal tree with lazy finger, one can know if such a structure is appropriate for a particular application or whether one should instead use the more powerful dynamic trees, or simpler root-finger trees.

Concurrency becomes a real issue in dynamic trees, which requires another layer of complexity to resolve (see, for example [\cite=DBLP:conf/ppopp/BronsonCCO10]), while static trees trivially support concurrent operations. Moreover, if several search sequences from several sources are interleaved, any dependence the pervious operation is destroyed by the interleaving. However, it is easy to have each sequence have it own lazy finger into a static tree, that allows each search sequence to be executed concurrently while not losing the ability to take advantage of any distributional temporal cohesion in each search sequence source.

Weights give a tree

Given a set of weights [formula], there is a randomized method to choose a tree TW such that the expected runtime is

[formula]

The method to randomly create TW is a straightforward random tree construction using the weights: recursively pick the root using the normalized weights of all nodes as probabilities. Thus, by the probabilistic method [\cite=DBLP:books/wi/AlonS92], there is a deterministic tree, call it [formula] whose runtime over the sequence X is at most the runtime bound of Seidel and Agraon for the sequence X on the best possible choice of weights.

There is a tree [formula] such that

[formula]

This follows directly from Seidel and Aragon, where [formula] is a tree that achieves the expected runtime of their randomized method for the best choice of weights.

Trees can be represented by weights

For all trees T there is a set of weights [formula] such that for all i,j

[formula]

These weights are simple: give a node at depth d in T a weight of [formula]. Consider a search that starts at node i and goes to node j. Such a path goes up from i to [formula] and down to j. A lower bound on [formula] is the weight of [formula] which is included in this sum and is [formula]. Thus we can bound [formula] as follows:

[formula]

For any tree T

[formula]

.

Follows directly from Lemma [\ref=treeweight], summing over the access sequence X, and noting that replacing the weights WT with minimum weights can only decrease the right hand side.

Proof of main theorem

Here we combine the results of the previous two sections to show that the runtime of the optimal tree with lazy finger, LF(T), is asymptotically the weighted dynamic finger bound for the best choice of weights.

[formula]

We start by defining Tmin(X) to be the optimal tree. Let

[formula]

Then, the runtime of Tmin is at most the runtime of any other tree, including [formula]:

[formula]

We now proceed with the main proof. By Corollary [\ref=c:tree]:

[formula]

Hierarchy and limitations of models

In this section we show there is a strict hierarchy of runtimes from the root finger static BST model to the lazy finger static BST model to the rotation-based BST model. Let OPT(X) be the fastest any binary search with rotations can execute X.

For any sequence X,

[formula]

Furthermore there exist classes of search sequences of any length m, X1m and X2m such that

[formula]

and

[formula]

We address each of the claims of this theorem separately.

Root finger can be simulated with lazy finger: [formula].

For lazy finger, moving up to the LCA and back down is not more work than than moving to the root and back down, which is exactly double the cost of the root finger method.

Lazy finger can be simulated with a rotation-based tree: [formula].

The normal definition of a tree allowing rotations has a finger that starts at the root at every operation and can move around the tree performing rotations. The work of [\cite=icalp] shows how to simulate with constant-factor overhead any number of lazy fingers in a tree that allows rotations in the normal tree with rotations and one single pointer that starts at the root. This transformation can be used on a static tree with lazy finger to get the result.

Some sequences can be executed quickly with lazy finger but not with root finger: There is a X1m such that [formula].

One choice of X1m is the sequential search sequence [formula] repeated until a search sequence of length m is created. So long a m  ≥  n, this takes time O(m) to execute on any tree using lazy finger, but takes Ω(mlgn) time to execute on every tree using root finger.

Some sequences can be executed quickly using a BST with rotations, but not with lazy finger.

Pick some small k, say k = lgn. Create the sequence X2m in rounds as follows: In each round pick k random elements from 1..n, search each of them once, and then perform n random searches on these k elements. Continue with more rounds until at total of m searches are performed. A splay tree can perform this in time O(mlgk). This is because splay trees have the working-set bound, which states that the amortized time to search an item is at most big-O of the logarithm of the number of different things searched since the last time that item was searched. For the sequence X2m, the n random searches in each round have been constructed to have a working set bound of O(lgk) amortized, while the k other searches in each round have a working set bound of O(lgn) amortized. Thus the total cost to execute X2m on a splay tree is [formula] which is O(mlglgn) since k = lgn.

However, for a static tree with lazy finger, X2m is basically indistinguishable from a random sequence and takes Ω(mlgn) time. This is because the majority of the searches are random searches where the previous item was a random search, and in any static tree the expected distance between two random items is Ω(lgn).

A BST in any model cannot reach the conditional entropy.

Wilber [\cite=DBLP:journals/siamcomp/Wilber89] proved that the bit reversal sequence is performed in Ω(nlgn) time in an optimal dynamic BST. This sequence is a precise permutation of all elements in the tree. However, any single permutation repeated over and over has a conditional entropy of 0, since every search is completely determined by the previous one.

Constructing the optimal lazy finger BST

Recall that fa,b = fX(a,b) is the number of searches in X where the current search is to b and the previous search is to a, and fX(a) is the number of searches to a in X. We will first describe one method to compute the cost to execute X on some tree T. Suppose the nodes in

[formula]

R(T,X,a,b)=

[formula]

out to the rest of T or vice-versa (e).

This formula can easily be adjusted into one to determine the optimal cost over all trees--since at each step the only dependence on the tree was is root of the current subtree, the minimum can be obtained by trying all possible roots. Here is the resultant recursive formulation for the minimum number of edges traversed in and among all subtrees containing

[formula]

min R(T,X,a,b)=

[formula]

Multiple trees structure

Here we present a static data structure in the comparison model on a pointer machine that guarantees an average search time of O(Hc(fX) log dn) for any fixed value 1  ≤  d  ≤  n, a runtime which we have shown to be impossible for any BST algorithm, static or dynamic. This data structure requires O(dn) space. In particular, setting d = nε gives a search time of O(Hc(fX)) with space O(n1 + ε) for any ε > 0.

As a first attempt, a structure could be made of n binary search trees [formula] where each tree Ti is an optimal static tree given the previous search was to i. By using tree Txi - 1 to execute search Ti, the asymptotic conditional entropy can be easily obtained. However the space of this structure is O(n2). Thus space can be reduced by observing the nodes not near the root of every tree are being executed slowly and thus need not be stored in every tree.

The multiple trees structure has two main parts. It is composed first by a complete binary search tree T' containing all of S. Thus the height of T' is O(lgn). The second part is n binary search trees [formula]. A tree Ti contains the d elements j that have the greatest frequencies fX(i,j); these are the j elements most frequently searched after that i has been searched. The depth of an element j in Ti is [formula]. For each element j in the entire structure we add a pointer linking j to the root of Tj. The tree T' uses O(n) space and every tree Tj uses O(d) space. Thus the space used by the entire structure is O(dn).

Suppose we have just searched the element i and our finger search is located on the root of Ti. Now we proceed to the next search to the element j in the following way: Search j in Ti. If j is in Ti then we are done, otherwise search j in T'. After we found j either in Tj or T' we move the finger to the root of Tj by following the aforementioned pointer.

If j is in Ti then it is found in time [formula]. Otherwise if y is found in T', then it is found in O(lgn) time. We know that if y is not in Tx this means that optimally it requires Ω(lgd) comparisons to be found since Tx contains the d elements that have the greatest probability to be searched after that x has been accessed. Hence every search is at most O(lgn / lgd) times the optimal search time of [formula]. Thus a search for xi in X takes time [formula] Summing this up over all m searches xi in X gives the runtime to execute X:

[formula]

We summarize this result in the following theorem:

Given the pairwise frequencies fX and a constant d, 1  ≤  d  ≤  n, the multiple trees structure executes X in time O(mHc(fX) log dn) and uses space O(nd).

We conjecture that no pointer-model structure has space O(n) and search cost O(Hc(fX)).