moGrams: A Network-based Methodology for Visualizing the ​​Set of Non-dominated Solutions ​in Multiobjective Optimization

Introduction

Most of the real-world problems have a multicriteria nature (i.e. they include several conflicting criteria) [\cite=Chankong83]. Multiobjective (MO) optimization methods are designed for solving and produce a set of non-dominated solutions [\cite=Coello07] [\cite=Deb01] when tackling these problems. Decision makers (DMs) aim at selecting the best possible solution from the set of returned alternatives. To do so, the DM has to compare the alternative solutions and that is a difficult and time-consuming task. In evolutionary multiobjective optimization (EMO) [\cite=Coello07] [\cite=Deb01] some authors define a global framework considering multicriteria decision making (MCDM) as a conjunction of three components: search, preference trade-offs, and visualization [\cite=Bonissone08].

A helpful visualization process in EMO should provide a deeper understanding of the problem and new useful information regarding the alternatives. The DM should receive as much relevant information as possible provided by powerful methods and techniques (e.g. networks and other visualization tools). A good visualization enables her/him to obtain more insights of the problem and the different solutions to identify differences and similarities before coming to the final decision [\cite=Miettinen14]. In particular, the flexibility (i.e., the ease to change one solution by another in the decision space) is an important property to respond to frequent environmental changes in many managerial and operation research problems in which the information is uncertain [\cite=Chica16OMEGA]. Additional information about the flexibility of the non-dominated solutions will be really worthy for the DM.

There is an increasing number of studies demonstrating that visualization combined with optimization can promote design innovations and provide DMs with an improved understanding of the problem [\cite=Fleming05] [\cite=Stump03]. The visualization of solutions in MO optimization is an active research area [\cite=Walker13] [\cite=Tusar15] and most of the works are devoted to visualization of the Pareto front in the objective space (see for example [\cite=Lotov04] [\cite=Kollat07] [\cite=Kurasova13]). Recent studies focus on how to represent non-dominated solutions for many-objective problems (i.e. those having more than three objectives) [\cite=Walker13]. However, just a few proposals deal with the visualization of the MO solution in the design space (e.g. self organization maps [\cite=Obayashi05], heatmaps [\cite=Pryke07], cloud visualization [\cite=Eddy02] or hyper-space diagonal counting [\cite=Agrawal04]). Up to our knowledge, there has not been any previous proposal providing the DM with insights about the relationships between the solutions in the decision space with the aim of helping the decisor to understand the problem and assisting to choose the final solution.

In this paper, we aim at proposing a novel methodology, called moGrams, for visualizing and analyzing MO solutions in order to facilitate the MCDM process. Our novel framework provides a clear insight of the design space by showing the relations among the obtained MO solutions in a network representation. Moreover, moGrams provide objective space information of the solutions in a joint visualization of both design and objective spaces.

A moGram is a weighted network where its nodes represent non-dominated solutions and its edges represent design space relations between the solutions. A similarity metric is used to generate the weighted edges of the network. This metric is defined by the DM and is specific to the MO problem. This is thus a generic methodology that applies to any multicriteria problem where its solutions can be related by a similarity metric. Also, moGrams deal with the scalability problem as multiple solutions with many objectives are shown in a salient way. In particular, every node (a non-dominated solution) is splitted into a number of sectors that corresponds to the number of objectives of the MO problem.

Our network-based proposal also enhances the similarity analysis of the solutions in the decision space. The analysis facilitates the evaluation of the flexibility of every solution. For instance, the DM would prefer a very connected node within the network. This is because that solution (represented by the node) could be easily transformed into an adjacent solution (high similarity in the design space).

moGrams use social network analysis (SNA) techniques to improve the visual information from the network [\cite=Scott2000] [\cite=wasserman1994social]. In particular, the Pathfinder algorithm [\cite=Dearholt90] [\cite=Sch89] reduces the complexity of the network by only representing the most salient connections, making its analysis easier. In order to clearly visualize the network, a force-directed layout is used, namely the Kamada-Kawai algorithm [\cite=MoyaAnegon07]. moGrams is also an interactive visualization framework where the DM has the possibility to obtain a clearer view of the network according to her/his preferences.

In order to show the benefits and versatility of moGrams we perform a complete experimentation on three MO problems. These three MO application cases come from different research fields and we choose them because of their different features (e.g. their decision variables are very diverse, from combinatorial optimization to real parameters). The first MO application case is the time and space assembly line balancing problem (TSALBP) [\cite=Chica10Ins] [\cite=Chica11CAIE] which deals with the joint optimization of the number of stations and their area when configuring an industrial line for assembling products. The next one considers the overproduce-and-choose strategy (OCS) [\cite=Partridge96] for classifier ensembles (CEs) [\cite=Kun04]and it aims at obtaining CEs with a low number of base classifiers, keeping a good accuracy [\cite=Trawinski11] [\cite=Trawinski2013]. The last application case focuses on the inductive query by example (IQBE) [\cite=Cordon2006]. IQBE is a paradigm that allows a system to automatically derive queries for a specific information retrieval system, defined as a MO problem with a conflicting precision-recall trade-off.

The rest of the paper is structured as follows. Section [\ref=sec:background] reviews the state of the art in MO visualization and a background of SNA. Section [\ref=sec:mograms] provides a description of our novel visualization proposal. In order to show usefulness of moGrams, Sections [\ref=sec:appcase1], [\ref=sec:appcase2] and [\ref=sec:appcase3] present three application cases including TSALBP, CEs and IQBE, respectively. Finally, Section [\ref=conclusions] outlines concluding remarks and future research works.

Background

Visualization of Multicriteria Solutions

There are multiple proposals for visualizing the MO and many-objective Pareto front solutions in the literature [\cite=Walker13]. Probably, the most common method for visualizing MO solutions is a scatterplot [\cite=Chambers82]. One of the most popular choices for many-objective solutions is the use of parallel coordinate plots [\cite=inselberg09]. Recent reviews [\cite=Walker13] [\cite=Tusar15] show that most of the works in the literature are devoted to the visualization of MO Pareto front solutions in the objective space.

The visualization of multicriteria solutions in the design space did not receive much attention indeed. We present a summary of the reviewed proposals in Table [\ref=table:soa]. First and second columns include the reference and visualization method used, respectively. The third column indicates the additional algorithms used to either obtain a clearer visualization (e.g. hierarchical clustering, spectral seriation) or provide additional numerical information (e.g. ANOVA, data mining classification). Only some proposals considered a joint visualization for objective and design spaces (fourth column). None of these works were focused on the similarities between the solutions in the design problem space (penultimate column) and none of them used a network as a tool for visualization of the MO solutions (last column).

Self-organizing maps (SOMs) attracted attention as a novel means for visualization of both objective and design space. SOM projects multidimensional data on a 2-D map without any information loss. In [\cite=Obayashi05] [\cite=Jeong05], SOM was applied to find the trade-offs between objective spaces, relationships between objective spaces and design variables. In both contributions, analysis of variance, namely ANOVA, was used to show the effect of each design variables on objective functions in a quantitative way.

In a different manner, Pryke et al. introduced in [\cite=Pryke07] a heatmap for presenting both the objective and parameter space in the same view. A hierarchical clustering was used to alleviate the transparency issue. Walker et al. [\cite=Walker13] also used heatmaps for MO visualization and improved their readability by using spectral seriation which rearranges the objective or parameter space views on the heatmap.

Agrawal et al. [\cite=Agrawal04] [\cite=Agrawal06] presented an intuitive visualization methodology for multidimensional MO optimization problems by using the hyper-space diagonal counting which enables a lossless mapping of dimensions. The proposed method dealed with more than three objectives and also with design space visualization.

There are some proposals providing a visualization of both objective and decision spaces in separate windows such as cloud visualization [\cite=Eddy02] and synchronous visualization [\cite=Jeong07]. The visualization frameworks, VIDEO [\cite=Kollat07] and EVOLVE [\cite=Kubota14], followed the same idea. They used standard techniques such as spatial coordinate axes, color, Kriging mapping in VIDEO; and scatterplot with Parallel Coordinate Plot in EVOLVE.

Besides, we can highlight other interesting proposals where authors presented each objective and design variable in separate windows (level diagrams) [\cite=Blasco08] or showed several three dimensional visualizations with fixed values of some design variables (graph morphing) [\cite=Winer02].

Social network analysis

The use of SNA techniques has proved its capability to achieve high quality, schematic visualizations of the resulting network-based representations in various fields: psychology (to represent the cognitive structure of a subject [\cite=Dearholt90] [\cite=Sch89]), system behavior (for designing and analyzing fuzzy systems [\cite=PanchoIEEETFS2013]), scientometrics (for the analysis of large scientific domains [\cite=Vargas2007visualizing]). Among others, SNA techniques are especially useful to solve two tasks:

Network scaling

Networks are usually dense and scaling is necessary to obtain structures revealing the underlying organization, maintaining all the nodes but only the most important relations. Three predominant SNA alternatives to accomplish this task are presented in the literature [\cite=chen2003visualizing]: The first method discards edges with weights below a given threshold [\cite=zizi1994accessing]. This approach, although easy to implement, does not consider intrinsic structure of the underlying network. Thus, the transformed network may not show the nature of the original one. The second method extracts a minimum spanning tree of the network [\cite=noel2002visualization]. This guarantees a fixed number of edges (a number of nodes minus one), although it may not show the underlying information. The last method provides constraints on paths and removes the edges not satisfying them. The Pathfinder algorithm [\cite=Dearholt90] [\cite=Sch89] is one of the most popular, known for its mathematical properties associated to preservation of the triangular inequality. Some of these properties are the conservation of the edges, the capability of modeling symmetrical and also asymmetrical relationships, maintenance of sub-networks, as well as the representation of the most salient relationships from the data.

Network drawing

There are different SNA methods for automatic visualization of networks. Force-based or force-directed algorithms are the most widely used algorithms for drawing networks in the area of information science [\cite=battista1999graph] [\cite=kobourov2005force]. Their purpose is to locate the nodes of a network in a two or three dimensional space so that all the edges are approximately of equal length and there are as few crossing edges as possible, trying to obtain the most aesthetically pleasing view. Kamada-Kawai [\cite=KamadaKawai1989] and Fruchterman-Reingold [\cite=fruchterman1991graph] are their most representative methods of the network drawing family.

Our visualization proposal

In this section, we present our visualization framework. We first define and describe the generation of moGrams in Sections [\ref=sec:mogramsDef] and [\ref=sec:mogramsGen], respectively. Then, we show DM implications in Section [\ref=sec:dmimplic].

moGrams definition

A moGram is a network, that jointly presents the solutions of a MO problem in the objective space and their relationship in the design space. In particular, every node of the network represents a non-dominated solution in the objective space and its edges represent design space relations between the solutions. There are as many nodes as non-dominated solutions in the objective space. The formal definition of the moGram is as follows:

moGrams generation

To facilitate comprehension of the moGrams generation, we use an illustrative example presented in Fig. [\ref=fig:toyEx]. It shows the scatterplot visualization of the Pareto front approximation on the left-hand side and generated moGram on the right-hand side. The illustrative example is a minimization problem consisting of 7 non-dominated solutions with two objectives and a similarity metric for the design space.

The generation of a moGram is divided into the following four phases:

Design space visualization. We generate a complete network with weighted edges based on S (see Equation [\ref=eq:matrix]), a n  ×  n symmetric matrix which contains the similarity values for all the non-dominated solutions. To generate S we use the similarity metric Sim(a,b)∈[0,1] which is a function returning a value for the closeness between two solutions a and b in the design space. This similarity metric is defined by the DM and is specific for the MO problem. We present a numerical example in Equation [\ref=eq:matToyEx], which is a similarity matrix of the illustrative example (the most important edges are presented in bold font).

[formula]

[formula]

The edge weight is proportional to the similarity of the two solutions and a label indicating its value is drawn in the network. It is also illustrated by the thickness of the edge to highlight it in the visual representation. For instance, in the example from Fig. [\ref=fig:toyEx], it can be noticed that the edge between node 1 and 2 is thicker than the edge between node 2 and 7.

Objective space visualization. moGrams provide information regarding the objective space of the solutions obtained by using different colors and opacity. The number of nodes of the moGram corresponds to the number of non-dominated solutions. Every node is divided into nobj sectors of the same size, where nobj is the number of the objectives. One color is assigned to each objective whose transparency is proportional to the objective value of the given solution. Thus, moGrams allow the DM to get a detailed insight of the solution not only in the design space but also in the objective space. In the illustrative example (Fig. [\ref=fig:toyEx]), each node is divided in half (180 slices). We assign the orange color to the first objective (the upper half of the node), while the blue color represents the second objective (the lower half of the node). For example, solution 1 has a very strong orange color in the upper half and is white (the blue color is fully transparent) in the lower half. Thus, we can deduce that this node has a low value of the objective 1 and a high value of the objective 2, laying in the left upper extreme of the Pareto front approximation (as seen in the visualization of the Pareto front approximation).

Network scaling. The resulting complete network is usually unreadable due to the large number of edges in most of the cases. Thus, the Pathfinder scaling method [\cite=Dearholt90] [\cite=Sch89] is applied to S in order to reduce the network and maintain only the most significant edges. By doing so, Pathfinder also generates the adjacency matrix A of the network. As already said, the Pathfinder algorithm, has two important characteristics: 1) it retains the most important edges and 2) it does not produce the isolated nodes. Notice that, this phase deals with the scalability of the problem, as Pathfinder can deal with large networks and strongly reduces the number of connections between the nodes. Its results are demonstrated in Fig. [\ref=fig:toyEx], where Pathfinder reduces the number of edges from 21 (the complete network) to only 7.

Network drawing. Force-based algorithms are suitable to graphically visualize networks, as already mentioned in Section [\ref=sec:sna]. We use the Kamada-Kawai  algorithm, since it has been shown to work effectively when combined with Pathfinder for other problems such as system behavior [\cite=PanchoIEEETFS2013] and scientometrics [\cite=MoyaAnegon07]. Again, taking a look at the illustrative example, we can observe a salient and clear view of the solutions.

DM implications

moGrams allow a DM a certain interaction with the network generated in order to get more insights of the given problem and the different solutions to be compared. For example, DM can adjust the similarities between the nodes. When their values belong to a certain narrow range, all edges in a moGram will have almost the same thickness. By scaling the range of similarities, the modified moGram will provide a clearer view of the relationship between the nodes. Moreover, only the nodes with specific characteristics can be interesting for the DM. Thus, our framework allows to remove some nodes from the visualization. To accomplish that, the moGram generation has to be relaunched excluding the marked nodes. The DM can also remove the information regarding the objective space, if the decisor is only interested in having a view into the design space. In this case, all nodes will have one uniform color only.

Application case 1: assembly line balancing

Problem description

An assembly line consists of a set of m workstations and n different tasks, all of them requiring an operation time for their execution. These tasks divide the manufacturing of a production item. One usual and difficult problem is to determine how these n tasks can be assigned to m stations fulfilling certain restrictions (assembly line balancing (ALB) [\cite=Battaia13]). The goal of the TSALBP, a family of ALB problems, is to optimally assign tasks to stations with respect to some objectives (cycle time of the line or the number of stations and/or their area) in such a way that all the precedence, time, and/or spatial constraints are satisfied [\cite=Chica10Ins]. This assignment is called assembly line configuration and it is a solution for the problem.

One of the TSALBP variants is the multiobjective TSALBP-m/A which tries to jointly minimize the number of stations m of the assembly line and their line area (A) for a given product cycle time. This variant is a complex and realistic multicriteria problem in the automotive industry which favored the application of MO methods to solve it such as multiobjective ant colony optimization [\cite=Chica10Ins], EMO [\cite=Chica11CAIE], and memetic algorithms [\cite=Chica12EngAppAI].

All the latter methods are able to return a set of non-dominated solutions for a known demand of homogeneous products. However, as pointed out in [\cite=Chica13IJPE] [\cite=Chica16OMEGA], flexibility is an important asset to manufacturing firms to respond to changes in the environment and this flexibility also applies to the automotive industry and ALB. Providing DMs with additional information about how flexible a non-dominated solution is, would be valuable when making her/his decision. This flexibility can be seen as the number of changes to perform when moving from one solution to another in the decision space (measured by a similarity index between both solutions) also taking into account how objective values change.

Therefore, we can apply moGrams to the non-dominated solutions of the TSALBP in order to provide visual information about the difficulty involved in replacing one solution by another. Flexible solutions will facilitate that transition. Two TSALBP solutions (assembly line configurations) ψ1 and ψ2 are characterized by the assignment of n tasks to m1 and m2 workstations, respectively, and their station workloads are (Sψ11,...,Sψ1m1) and (Sψ21,...,Sψ2m2). Notice that TSALBP design variables belong to a combinatorial optimization problem. In order to calculate the similarity we first calculate the similarity of each station. A similarity index for each station k in the two line configurations is given by Equation [\ref=eq:sim-station].

[formula]

Taking into account the latter station similarity index, we define the similarity index Sim∈[0,1] to measure how different two line configurations ψ1 and ψ2 are in m stations, where m = max{m1,m2} (Equation [\ref=eq:sim-T]). Two assembly line configurations are completely similar when Sim(ψ1,ψ2)  =  1.

[formula]

moGrams analysis and DM implications

In Figure [\ref=fig:tsalbp1], we can observe a moGram generated for a TSALBP instance (420 tasks in a real automotive assembly line; see [\cite=Chica16OMEGA] for more details) with 13 solutions. The orange color represents the first objective, the number of stations, while the blue color shows the second objective, the area of the configuration line. Each edge has a label with its similarity value and its thickness depends on it.

The obtained moGram allows to get the following observations from the visualization network:

The existing edges present very diverse similarity values, 0.91 being the highest value, whereas 0.14 being the lowest one. The highest values (0.91 and 0.84) are obtained between nodes 1, 3 and 5, 6, respectively. In contrast, the edge between nodes 2 and 11 (0.136) obtains the lowest value. The edges between nodes 2, 7 and 11, 13 also have low similarity value (0.219).

We can distinguish three sub-networks based on the high similarity values between some pairs of nodes in the network. That happens at the top of the network (nodes 4, 8 and 12), at the bottom-right corner (nodes 9, 10 and 13) and also in the centre (nodes 2, 5, and 6).

A sub-network considering nodes 2, 5 and 6 (in the centre) is an interesting case. It is a fully connected sub-network with strong connections. The nodes 5 and 6 exhibit the highest similarity value (0.84), while their edges with node 2 have the same similarity (0.60).

From the moGram, a decisor can get important insights about the TSALBP solving. For instance, the following items are problem-specific conclussions drawn from the visualization:

Node 13 exhibits the lowest number of stations (represented by a fully opaque orange color). According to its edges, this solution can be transformed into the solution 10 and also 11. Notice that transition to node 11 is more costly, due to the lower similarity value.

Solutions 1 and 7 characterize the lowest area (second objective reaches a fully transparent value). The former is well-connected to its neighbor (the thick edge towards node 3) demonstrating very similar characteristics in the design space. On the other hand, solution 7 is directly connected with solution 2 with contrasting objective values.

The most central node is the solution 2. It can be easily transformed to solutions 5 and 6; and it is also linked to other nodes (nodes 7, 8 and 11) with different characteristics in the objective space. Although the similarity values between solution 2 and the latter nodes are low, it is very useful information. It shows the flexibility of the solution 2 if the configuration line needed to be transformed to put more emphasis in the other objective.

Application case 2: classifier ensembles

Problem description

Classifier ensembles (CEs), also called multiclassification systems, are machine learning tools capable to obtain better performance than a single classifier when dealing with complex classification problems, especially when the number of dimensions or the size of the data are really large [\cite=Kun04].

The overproduce-and-choose strategy (OCS) [\cite=Partridge96] (also known as test-and-select methodology [\cite=Sharkey00]) is based on the generation of a large number of component classifiers, and a subsequent selection (removing duplicates and poor-performing candidate classifiers) to extract the best performing subset which composes the final CE.

OCS methods aim at determining the optimal ensemble size by considering a trade-off between accuracy and complexity. The MO nature of this problem led researchers to use EMO algorithms and combine different measures in order to improve the accuracy-complexity trade-off of the final CE [\cite=Trawinski11] [\cite=Trawinski2013] [\cite=Oliveira05] [\cite=Santos08]. In this application case, we focus on the EMO OCS approach based on two basic conflicting objectives, accuracy and complexity [\cite=Trawinski11]. Accuracy is defined as the proportion of correctly classified examples among the total number of examples, while complexity is represented by the number of classifiers.

From the DM point of view, it is of huge interest to obtain flexible CEs. Depending on the current demands, they can be converted to either a more accurate or to a less complex system by just adding or removing base classifiers. In an environment with limited resources (e.g. limited memory), the DM is interested in a model with the lowest complexity. When the correct answer is of big importance (e.g. breast cancer classification), the DM will choose the most accurate model. Beyond the information provided by the Pareto front approximation, moGrams can be applied to the non-dominated CE solutions obtained in order to visually analyze their relationship in the design space, i.e. flexibility, centrality, among others.

The similarity metric uses information about the base classifiers composing the CE and is computed as follows. Two CE solutions ce1 and ce2 contain a subset of base classifiers from the initial pool of base classifiers (their total number is ncl). These solutions are coded in binary strings strce1 and strce2 in a way that a binary digit/value clk is assigned to each classifier that strce1  =  (clce11,clce12,...,clce1ncl) and strce2  =  (clce21,clce22,...,clce2ncl), respectively. When the value of clk is 1, it means that a given classifier is included in the final ensemble, while 0 stands for classifier exclusion. We use the normalized Hamming distance [\cite=hamming50] to compute the distance between two binary strings strce1 and strce2 (see Equation [\ref=eq:HamDist]).

[formula]

Then, the distance metric Hdistce(ce1,ce2) is subtracted from 1 in order to have a similarity measure Sim(ce1,ce2)∈[0,1] (see Equation [\ref=eq:SimHamDist]).

[formula]

moGrams analysis and DM implications

Following the same procedure described in Section [\ref=sec:mograms] a moGram is generated for an instance of a CE problem (the abalone dataset; see [\cite=Trawinski11] for more details) with 15 different solutions from the Pareto front approximation (Figure [\ref=fig:ensembles1]). The orange color is associated with the accuracy, while the blue color represents complexity. Since the edges present akin similarity values (their range is quite narrow), the final moGram visualization was previously adjusted by the user in order to represent similarities in a clear way.

The generated moGram offers a clear representation of the solutions in the design space and leads to the following observations. Unlike the previous application case (see Section [\ref=sec:appcase1]), the existing edges present high similarity values (all above 0.86). When looking for the most accurate solution, node 1 is the suggested choice. However, it is separated from the rest of the nodes in the design space. So, if a flexible but still accurate solution is desired, then solution 6 is the proposed one, as it is connected to solutions with different objective values and can be easily modified (high similarity values) to more accurate or less complex solution (Solutions 3, 5 and 15). In contrast, node 15 is the one having the less complex CE, but it is also isolated from the other nodes, as it has only one edge. Then, it is not the best choice when looking for flexibility.

Globally, the most flexible solutions are solutions 13 and 14, located in the centre of the network. They can be easily transformed to the other solution with different characteristics in the objective space. Finally, when looking for an accuracy-complexity trade-off solution, solutions 7 to 14 demonstrate these characteristics. Among them, solution 10 can be distinguished, as the most flexible one because it has the highest number of edges.

Application case 3: Boolean queries for information retrieval

Problem description

Information retrieval (IR) can be defined as the problem of selecting documentary information from a repository based on search queries introduced by a user [\cite=Salton86] [\cite=Baeza-Yates99]. In Inductive Query By Example (IQBE) [\cite=Chen98], a query is automatically generated, which describes the information contents of a set of documents provided by a user. Thus, it can be useful to assist the user in the query formulation process. The two most common criteria to measure the quality of IR system are precision and recall [\cite=Rijsbergen79]. Boolean queries are defined by a query language, which is composed of query terms and it is combined with logical operators AND, OR and NOT [\cite=Rijsbergen79].

As precision and recall are two conflicting criteria, the IQBE problem has a MO nature. In [\cite=Cordon2006] [\cite=Herrera09a] [\cite=Herrera09b], the authors formulated IQBE as a MO problem and tackled it using EMO algorithms, obtaining several queries with a different precision-recall trade-off.

Precision is a measure of exactness or quality, while recall measures completeness or quantity. Thus, the DM might be interested in obtaining either more relevant documents (high precision) or most of the relevant documents from the repository (high recall). The information about the flexibility of the solution is valuable for the DM before choosing the final solution. Therefore, moGrams can visually represent the mentioned flexibility of the solutions (i.e. how many changes are necessary to do in order to transform from a given solution to another).

Having two boolean queries bq1 and bq2 we consider them as strings in such a way that each term or operator of the boolean query is treated as a single entity/character eni1 and enj2 of the string, respectively. The similarity metric used is the edit or Levenshtein distance [\cite=levenshtein66] which measures the similarity between the generated boolean queries. Levenshtein distance aims at finding the cheapest way to transform one string into another. Transformations in Levenshtein distance are one-step based operations of insertion, deletion and substitution. Then, Levenshtein distance is computed by a dynamic programming algorithm and it is defined by the recurrence of Equation [\ref=eq:LevDist] (see [\cite=Navarro01] for more details).

[formula]

where 1(eni1  ≠  enj2) is the indicator function equal to 0 when eni1  =  enj2 and equal to 1 otherwise, while i and j are lengths of two compared boolean queries.

Then, the similarity metric Sim(bq1,bq2) is normalized and subtracted from 1 in order to reflect similarity instead of the distance as presented in Equation [\ref=eq:SimHamDist].

[formula]

with |bq1|, |bq2| being the number of entities in the boolean queries bq1 and bq2, respectively.

moGrams analysis and DM implications

Fig. [\ref=fig:booleanQueries] shows the moGram constructed for the IQBE problem (the Cranfield collection; see [\cite=Cordon2006] for more details). The orange and blue colors of nodes reflect precision and recall, respectively. In the light of this moGram, we can observe that:

We can uncover three subset of solutions at design space by observing the graphical representation:

Solution 1, which maximizes precision, is far from the rest of solutions conforming the first subset. Although it has 7 edges those values are very low in all the cases.

Solutions 2 to 20 are highly related each other and form a subset of solutions with good trade-off between precision and recall but without extreme values (except for solution 2).

Solutions 21 to 26 clearly maximize precision at the expense of reducing recall.

Although solution 1 obtains the best precision, alternatively solution 2 also reaches very good precision values and is much more flexible, highly connected with solutions 4, 5, 6 and 8. In case the flexibility is required, solution 2 is suggested when looking for high precision.

If we look for a high recall, we can choose any of the solutions from 21 to 26. However, solution 25 obtains high recall and it is flexible, therefore it is one of the best options.

Globally, the most flexible solution is 8 as it has connections to nine other alternatives. However, any of the nodes from 2 to 20 are also highly flexible, to be changed to other solutions.

Concluding remarks and future works

In this paper, we have proposed a novel methodology for visualizing and analyzing non-dominated solutions of MO problems. It provides the DM with a graphical exploration of the design space. In particular, it shows the relationships between the obtained solutions using a network. The so-called moGram presents several interesting characteristics: it gives a clear insight into the design space, it incorporates jointly visualization of both design and objective spaces, and it is a generic and scalable approach. While generating the visualization, the DM interaction is also possible. Our proposal is based on SNA techniques for constructing, scaling and drawing the network.

The moGrams methodology was applied to three MO problems coming from very different research fields such as time and space assembly line balancing, classifier ensembles and boolean queries for information retrieval. We have shown the capabilities of moGrams and how they can help the DM when choosing the final solution. Therefore, moGrams is a powerful visualization technique, which aids in the understanding of the problem and the similarities between the solutions. Additionally, groups of solutions or the most flexible ones are easily detected thanks to this network-based visualization.

There are several future research lines that can be investigated. First, we can apply SNA techniques to analyze moGrams in order to find the most significant nodes by using centrality measures such as centrality degree, closeness and betweenness for the nodes. Another opportunity is to apply community discovery algorithms to obtain clusters of solutions. We will also investigate the use of classical data mining techniques to obtain associations between the design space and the objective space for all the solutions of a problem. Finally, we would like to create an open Web tool for the generation and analysis of moGrams.