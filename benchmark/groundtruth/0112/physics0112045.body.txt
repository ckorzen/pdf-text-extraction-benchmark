=4mm =1000

Dynamics of market indices, Markov chains, and random walking problem

Introduction

At present, the economic data are easily accessible through Internet. The economic data are renewed on the monthly, weekly, and daily basis. During the sessions the data are renewed in the interactive regime, i.e. instantaneously. It is not a problem to get an access to the economic data anymore. The problem is to make sense of the available information.

During the last years, the possibilities for analyzing the data have been improved very much. Now, the memory of personal computers is sufficient to keep huge databases. The speed of the personal computers is high enough to work with these databases and run complicated codes. Also, the connection with Internet is fast enough to get within a reasonable time interval any desirable information. This situation is completely new one, as compared with the very recent past.

The progress in the personal computers and in the Internet services improved the possibilities of single programmers. One can expect that some of them will attempt to understand the economic data, too.

The description of stochastic process requires the knowledge of the probability theory and mathematical statistics. These mathematical tools are useful not only in the exact sciences [\cite=Chandrasekhar], but also in the social sciences [\cite=Wilks] [\cite=Portenko].

This work represents an attempt to apply methods of the probability theory and mathematical statistics for the analysis of the market dynamics. We are interested in finding statistically significant deviations from the purely stochastic market behavior. In particular, we are looking in historical quotes for signatures which allow to predict market moves with sufficiently high probabilities. We use these signatures further to develop a computer-based strategy of the market behavior.

We start in the next Sect. from description of the random walking problem in presence of a trend. This is an evident extension of the symmetric random walking discussed by Chandrasekhar [\cite=Chandrasekhar]. We calculate return and dispersion for the "buy-and-hold" (BH) strategy in terms of a trend parameter w which represents a probability of moving an index up for a day (week, month). Then, we determine from the historical quotes empirical values of the trend parameters for the daily, weekly, and monthly quotes of the four basic market indices of USA: Dow Jones Industrial Average (DJIA, analyzed years 1930 - 2000), Standard and Poor (S&P, analyzed years 1950 - 2000), Nasdaq (analyzed years 1985 - 2000), and New York Stock Exchange (NYSE, analyzed years 1965 - 2000).

In Sect. 3, we propose a more detailed model for dynamics of the market indices by taking into account two-step correlations of the subsequent market moves. Such a model represents a particular case of the Markov chains that have many useful applications in different fields. The model has two free correlation parameters, p and q, which are probabilities for a continuation of the market moves, respectively, up and down. We determine empirical values of these parameters from the historical quotes for the daily, weekly, and monthly data of the four basic market indices. These two-step correlations are found to be statistically significant. We calculate further return and dispersion for the BH and "follow-trend" (FT) strategies and compare their efficiency in the past. The problem of how to combine these two strategies to ensure the minimum of the dispersion (a minimum risk strategy) has an analytical solution. We found it using the theory of series [\cite=Wilks].

In Sect. 4, we calculate within the framework of the Markov chains approach the weekly and monthly correlation parameters P and Q in terms of the daily correlation parameters p and q. The results are compared with the empirical values. There are deviations of the calculated values from the empirical values, which indicate that the large-scale dynamics of the market indices is not fully determined by the short-scale dynamics. The renorm group relations are established between the correlation parameters at different time scales.

In Sect. 5, backtesting principles are discussed. We show that misuse of the backtesting can lead to systematic overestimates of the returns and give an example of such a misuse. We propose a special type of the backtesting, which is more realistic with respect to the estimate of the future performance. In this Sect., specific features of the market dynamics are used to construct a computer-based (CB) strategy based on a combination of the theory of series and Japanese candlesticks charting techniques. The CB strategy is backtested.

The results obtained in this work are discussed in Conclusion.

Random walking with trend

An excellent introduction to the random walking problem can be found in the Chandrasekhar's lectures [\cite=Chandrasekhar].

We consider random walking of a particle on a vertical infinite line. On each step, the particle makes a move up with a probability w or a move down with a probability 1 - w. The length of the jumps is everywhere the same and set equal to unity.

In order to arrive after N steps into a point with a coordinate

[formula]

the particle should make n+ = N - n- steps up and n- steps down. The probability of finding the particle with a coordinate z after N steps is described by the binomial distribution

[formula]

This distribution is normalized to unity:

[formula]

The dynamics of the market indices can be treated from the point of view of the random walking problem. If a market index is closed up for a day (week, month, ...), we say that the "particle" made a step up. If a market index is closed down, we say that the "particle" made a step down.

We analyzed the following data: DJIA (1930 - 2000 years), S&P (1950 - 2000), Nasdaq (1985 - 2000), and NYSE (1965 - 2000). In Table 1, the values of w are shown for the daily (W1), weekly (W5), and monthly (W21) quotes of these indices. The meaning of other parameters in Table 1 is explained in the next Sects. In the meantime notice that the values of w everywhere are quite close to 1 / 2. This case of the random walking is discussed by Chandrasekhar [\cite=Chandrasekhar].

As compared to his lectures, we discuss more general case and introduce a trend parameter w that can be different from 1 / 2. The deviation of the daily parameter w from the symmetric value 1 / 2 is statistically significant. Indeed, the accuracy of the numbers given in Table 1 is determined for the daily quotes by the value of [formula] where ND = (the number of the working days per year)  ×  (the number of years analyzed). For DJIA index, the statistical error equals 0.7%. The deviation of the daily parameter w = 0.5339 from the symmetric value w = 1 / 2 is 6.78% i.e. 10 times greater. It is safe to conclude therefore that the trend does exist. The statistical errors are shown in Table 1 for all indices for the daily, weekly, and monthly quotes. Notice that according to the estimate of ref. [\cite=Colby], p. 141, based on the analysis of the 1952 - 1983 years, the DJIA daily trend parameter equals w = 0.521. This result is close to ours.

We analyze finite samples of the data, and so an attempt to find a statistical law can always result in finding a statistical fluctuation. Such an unwanted possibility always exists and cannot be excluded. Maximum what can be done is to reduce risk of the misinterpreting the data. In addition, we deal with an alive system. Even if it is described by a statistical law, parameters of the corresponding distribution can be time dependent. If the rate of accumulation of the data (day-by-day, week-by-week, ...), which we clearly cannot influence, is lower than the rate of variation of the system parameters, the system parameters cannot be determined from the observations. There always exists an uncertainty.

The statistical methods are, however, widely used in the social sciences, despite they are less reliable than in the exact sciences. In this work, we want to reach some clarity concerning a few basic features of the market behavior in the past. We do not discuss if these feature will remain in the future markets.

The very important characteristics of a market index is its return. In our simplified model, return is nothing but the number of the moves up minus the number of the moves down. This quantity looks like

[formula]

We have here the difference of the steps up (w) and down (1 - w). This is, equivalently, the average value of the parameter z = n- - n+ in the binomial distribution ([\ref=binom]).

We refer this passive strategy as "buy-and-hold" strategy. Notice that

[formula]

and so the dispersion of the value z = n- - n+ equals

[formula]

Random walking with two-step correlations

In order to reveal less trivial statistical features of the market dynamics, we should consider a possibility for existence of correlations between the subsequent moves. In other words, we want to check if there is a memory about past when an index makes a move.

In the simplest case, the memory effect is described by four conventional probabilities

[formula]

which depend on two independent parameters p and q. We refer these parameters as correlation parameters. The signs [formula] and [formula] denote moves up and down.

We would like to deal with a homogeneous system with respect to the time translations. It means that any particular sample of the data should give identical results for the trend parameter w and the correlation parameters p and q. The homogeneous condition looks like

[formula]

It shows that the value of w remains invariant under the time translations. It becomes evident if eq.([\ref=homo]) is rewritten in the form

[formula]

Here, [formula] and [formula], while the conventional probabilities are from eqs.([\ref=p.and.q]).

Therefore, as long as the parameters p and q are known, the trend parameter is fixed:

[formula]

If the homogeneous condition ([\ref=homo]) is not fulfilled, the problem makes sense, too. The difference is only that the parameters p and q determined from the first half of the data could be different from the same parameters determined from the second half of the data. Such a possibility is not discussed here.

In Table 1, the trend parameters Wk and the correlation parameters Pk and Qk are shown for k = 1 (daily data), 5 (weekly data), and 21 (monthly data) for the four major USA market indices. The empirical values are determined by fitting the distribution of number of the sequential series for the up- and down-moves under the imposed homogeneity condition ([\ref=homo] The statistical errors are also shown. The meaning of the "calculated values" Wk, Pk, and Qk is explained in Sect. 4. The weekly and monthly data are discussed in the details in Sect. 4.

The main observation that can be made at the moment is the existence of the correlations between two consequent steps of the market indices in the daily data. These correlations are not strong, but statistically significant. The lack of the correlations would mean p  +  q  =  1 and w = p. To the first approximation, the market dynamics can be treated as the random walking without trend (w = 1 / 2). To the next approximation, it can be treated as the random walking with a trend (w  ≠  1 / 2). The next approximation takes into account the two-step correlations, and these correlations are also statistically significant.

In Table 2, we compare χ2 for the ratios between the empirical number of the up- and down-series and the number of the analogous series for the random walking in three models: The symmetric random walking w = 1 / 2, the random walking with trend (w  ≠  1 / 2), and the random walking with trend and correlations. It is seen that for the daily quotes the χ2 for the third model is 5 to 15 times less than for the first two models for the up-series and is comparable with the first two models for the down-series. We consider it as a clear evidence for the existence of the two-step correlations. The equation p + q = 1 can also be treated as a criterion for the existence of the two-step correlations. For the daily quotes, it is not fulfilled, as one sees from the Table 1. The similar check can also be made for the equation w = p which is an equivalent criterion for the existence of the correlations.

There are deviations from the geometrical distribution of the number of the series of a fixed length. In Tables 3, 4, and 5, we show the daily (D), weekly (W), and monthly (M) empirical values p*k together with the statistical errors for probabilities of continuation of the series

[formula]

with nk  being the number of the up-series of the length k. So, if we have k - 1 moves up, the probability to have the next move up is p*k. The similar expression holds true for the values q*k that describe the probability for continuation of the series down. The results are shown for the four basic market indices of USA. The numbers typed in boldface deviate more than others from the symmetric values p  =  q  =  1 / 2. They approach 1, signaling continuation of the series with a high probability, or approach 0, signaling the end of the series with a high probability.

Notice that Nasdaq during the 1985 - 2000 years did not fall off more than 6 weeks in raw in the weekly quotes and more than 4 month in raw in the monthly quotes. Last time Nasdaq was down 4 months in raw in the period September 2000 - December 2000. Using the results of Table 5, one could predict with certainty (with unit probability) a positive move of Nasdaq for January 2001. Such a prediction would be the correct one.

Let us calculate return of the follow-trend (FT) strategy: We buy an index the next day when it is closed up for the first time after one or several days down and sell it the next day when it is closed down for the first time after one or several days up. The return equals

[formula]

In order to derive eq.([\ref=R2]), one should consider the problem in more details:

In the sample of all events, there are [formula] series of the length j, in which all j events are moves up. Similarly, there exist [formula] series of the length j, in which all j events represent moves down. In the both cases, the value of j varies from 1 to +    ∞  , in the limit of N  →    +    ∞  . In what follows, we set N =  +   ∞  . The finite values of N if appear imply the leading order at N  →    +    ∞  .

The probability of finding up-series of the length j in the set of all up-series is apparently described by the geometrical distribution

[formula]

This distribution is normalized to unity. The same distribution is valid for description of the down-series of the length j in the set of all down-series

[formula]

The average number of events in the series can easily be found to be

[formula]

It is evident that the number of series [formula] of the length j in a sufficiently large sample is proportional to the probability of finding the same series, so one can write

[formula]

Since the number of all up- and down-moves is known,

[formula]

where < n+ >  +  < n+ >  = N, the coefficients C±   appear to be determined. The average number of the series of the first and second kind equals

[formula]

Notice that due to the homogeneity condition ([\ref=homo]),

[formula]

The return for the FT strategy represents a sum of the number of the series [formula] multiplied by the return j - 2 of the j-th series plus the analogous term for the down-series:

[formula]

With the help of eqs.([\ref=ar.p]) and ([\ref=ar.m]) we obtain eq.([\ref=R2]).

In order to find the dispersion of the value R2, it is necessary to perform additional constructions in the spirit of the theory of series encountered in the mathematical statistics (see e.g. [\cite=Wilks]). A part of the necessary constructions is already done above. The additional efforts are justified since the dispersion represents an important characteristics of every strategy.

The value of N is assumed to be large and finite. The probability of finding a sample characterized by the values [formula] and [formula] can be written as follows

[formula]

The combinatorial factor is the number of different ways to order [formula] up- and [formula] down-series in the sample characterized by the sets of the numbers [formula] and [formula] The combinatorial factor is multiplied further to a probability of finding the one concrete configuration.

Each sample contains n+ up- and n- down-moves. The value pn+ is, in principle, a probability of finding n+ up-moves. However, the first moves of the series appear every time with probability of 1 - q. There are [formula] such moves, one move per one series. The correct probability to have n+ up-moves is therefore [formula] and similarly for the down-moves. In this way, the rest terms in eq.([\ref=W]) are reproduced.

The very first and the very last elements of the whole sample play a special role, so we should separately discuss the boundary conditions.

First of all, it is evident that the [formula] can differ from the [formula] at most by one unit. For [formula] the sample starts and ends up with up-moves. We set for [formula] the probability of finding the first move up equal to zero. For [formula] the sample starts and ends up with down-moves. For [formula], the probability of finding the first move down is set equal to zero either. For [formula] there are two samples, the one of which starts with an up-move, and another one starts from a down-move. The probabilities of finding the first elements in these two configurations are selected as would the problem is formulated for a periodic chain: In the first case the probability of the first element equals 1 - q, while in the second case the probability of the first element equals 1 - p. Now, the problem is well formulated. In what follows we denote [formula].

The boundary conditions are, clearly, not unique. We are interested, however, by the limit of large N where the effects of the boundary conditions are not important. The above description is needed to formulate unambiguously the problem.

Now, we are in a position to find the dispersion of the return R2. Let us sum up the probability [formula] over the numbers [formula] and [formula] keeping, however, the values [formula] [formula] n+, and n- fixed. It can be done with the use of the method described in ref. [\cite=Wilks]. We obtain

[formula]

The asymptotic form at [formula] n+, and n- >  > 1 of the [formula] is given by

[formula]

A simple calculation shows that [formula], in agreement with eqs.([\ref=ar.p]) and ([\ref=ar.m]), < n+  >   and < n-  >   are defined by eqs.([\ref=an.p]) and ([\ref=an.m]), and

[formula]

The dispersion of the value R1 = 2n+ - N is determined by the dispersion σ21 of the value n+, that equals

[formula]

Notice that this value differs from the value of eq.([\ref=S1]) where the two-step correlations are not taken into account. Respectively,

[formula]

The dispersion of the value R2 = N - 4r is determined by the dispersion σ22 of the value [formula]:

[formula]

Respectively,

[formula]

The problem is solved. It remains to compare the relative efficiency of these two strategies. The results are placed in Table 6.

By comparing the values given in Table 6, one can conclude that in the daily regime for all the indices the FT strategy is more efficient, since it has better return with dispersion close to the one of the alternative BH strategy. Here, however, transaction costs are not taken into account.

One can expect that combining two strategies decreases the dispersion. This is not always the case. Let us assume that funds invested to two strategies are in the ratio α:β, with α  +  β = 1. The return of the combined strategy equals

[formula]

In order to calculate dispersion, one should take into account the correlation between the values R1 and R2. We obtain

[formula]

The minimum of ΔR23 is achieved either at the boundaries α = 1 (BH strategy), α = 0 (FT strategy), or at that value of α where the first derivative of ΔR23 with respect to the α vanishes. In the last case, one should require (i) 0 < α < 1 and (ii) the second derivative is positive. In the case of a boundary minimum, the combination of the two strategies does not result in a decrease of the dispersion. In the second case, the dispersion can be decreased.

The combination of the BH and FT strategies appears to be constructive: The conditions (i) and (ii) are satisfied. In Table 6, we give values of the mixing parameter α, the return R3, and the dispersion of the combined strategy with the lowest possible dispersion. The minimum of the dispersion is not an obligatory requirement. The value of α is selected as a compromise between the highest possible return and the minimum possible risk. The above estimates show the limits within which these parameters (return and dispersion) can be changed.

Is large-scale dynamics determined by short-scale dynamics?

We can combine successive moves in pairs, triplets, and so on. The each group of k events (k = 1,2,...) corresponds to a move up or down, according as the total displacement of the index is the positive one or the negative one. We wish to find parameters Wk, Pk, and Qk which describe the probability of finding a group of the k events in the state "up", and, respectively, the conventional probabilities to find two such successive groups in the states "up" and two successive groups in the states "down".

The problem is motivated by the fact that participants of the market make transactions with different frequencies: once per minute, once per hour, ... , up to once per month and once per year. In the last case e.g. the change of the index during one month can be treated as an elementary move. The problem of finding parameters Wk, Pk, and Qk with k > 1 in terms of the parameters w, p, and q of the smallest time interval, has a unique formal solution, as long as the model is clearly formulated. In the view of the specific feature of the market, it is absolutely not apparent, however, that the large-scale dynamics is determined by the short-scale dynamics. The short-term traders take into account the behavior of the long-term traders, since the long-term traders are usually the institutional ones. From other side, the long-term investors take into account the short-term behavior of the market.

Here, our purpose is to check to what extent the large-scale dynamics is determined by the short-scale dynamics. It can be done as follows: We calculate parameters Wk, Pk, and Qk in terms of the parameters w, p, and q, determine parameters Wk, Pk, and Qk from the historical quotes, and compare the two groups of the values.

Weekly and monthly parameters in terms of daily parameters

Let k be the number of moves (days) in the group. The probability of finding the group of k moves "up" is given by

[formula]

where

[formula]

The additional factor [formula], as compared to eq.([\ref=W]), appears because of new boundary conditions. The first up event comes with a probability w, the first event down comes with a probability 1 - w, [formula] coincides with [formula] or differs from [formula] by one unit. The factor

[formula]

where

[formula]

The first term in eq.(4.3) corresponds to the case when in the group of k events the first move is an up-move, while the second term corresponds to the case of a down-move. In eq.(4.1), respectively, n+ and n- are the numbers of the moves up and down in the group. Apparently, n+ + n- = k. The values [formula] and [formula] give the number of the series up and down in the considered group.

For an even k, a situation is possible when total displacement is equal to zero, n+ = n-. In such a case, it is necessary to specify separately the meaning of the up and down moves for groups of the k events. We assign the probability of 1 / 2 for interpreting neutral move as a move up and the probability of 1 / 2 for interpreting neutral move as a move down. For even k, the summation in eq.(4.1) extends to n+ = n- with the weight of 1 / 2. The normalization factor in eq.(4.1) should be equal to unity according to the construction.

The probability that the second group of k events has the value "up", provided that the first group has the value "up" also, can be found from equation

[formula]

where the ratios W+  +(p,q,k) / W(p,q,k) and W+  -(p,q,k) / W(p,q,k) are the probabilities that the last events in the up-groups are, respectively, moves up and down. The values W+  +(p,q,k) and W+  -(p,q,k) are calculated as follows:

[formula]

where

[formula]

[formula]

Eq.(4.7) can be explained in the following way: The last move in the group of k moves is a move up provided that [formula] Else, it is a move up also at [formula] provided that the first move in the group is a move down. In the first case, the first move is a move up, and so the probability [formula] should be divided by 1 - q and multiplied by w. In the second case, respectively, the probability should be divided by 1 - p and multiplied by 1 - w.

The value Q(p,q,k) can be found in the similar way:

[formula]

where

[formula]

It is evident that

[formula]

One can show that the homogeneous condition ([\ref=homo]) is satisfied for the values W, P, and Q.

Since the algorithm for construction of the quantities W, P, and Q is simple, the numerical solution can be found quite easily.

In Table 1, we place the calculated values W, P, and Q for k = 5 (weekly quotes) and 21 (monthly quotes), the values w, p, and q are determined from fitting the daily quotes. We show also the empirical values of W, P, and Q determined from the historical weekly and monthly quotes. In Table 2, the values of the χ2 are shown for the empirical weekly and monthly quotes for three models of the random walking, discussed in the previous Sect. These quotes are analyzed in the same way as the daily quotes.

The comparison of the calculated and empirical values W, P, and Q shows quite good agreement for the weekly quotes. A noticeable deviation exists only for Nasdaq in the value Q5. When the index falls down, a stronger than expected correlation exists: The probability of the continuation of the down-moves exceeds the calculated value. The system easily evolves from "bad state to worse state" (Parkinson Law).

In all other cases, the agreement of the weekly parameters W, P, and Q with the calculated values is satisfactory. One can conclude that at the daily-weekly scale, the short-scale dynamics (daily behavior of the indices) determines the large-scale dynamics (the weekly data).

Let us compare now the calculated monthly parameters W, P, and Q with the empirical values. We see that the values Q21's are essentially underestimated for all indices. We observed such an effect already for the weekly quotes of Nasdaq. In the monthly quotes, the effect is much more pronounced. At the same time, the calculated values W and P coincide within one-two standard deviations with the empirical values.

We conclude that the large-scale dynamics (monthly behavior) is determined by the short-scale dynamics (daily behavior) only partially. It is quite different from what we have in physics. On the monthly scale, there are substantial deviations from the random walking if the memory on the past is, as we assumed, restricted by the previous day only. It is also interesting that the values W and P calculated within the framework of such a simple model are in reasonable agreement with the empirical values.

Renorm group in random walking problem

There is a renorm group relation between parameters W, P, and Q:

[formula]

These relations can be used to establish the form of the functions P and Q with the help of the boundary conditions

[formula]

The algorithm described in the previous Sect. can be used to construct functions P and Q for positive integer k. In the renorm group equations, we can set k = 1 / l and find functions P and Q for k = 1 / l. We set afterwards k = 1 / m where m is an arbitrary integer number and obtain the functions P and Q for all rational values of the arguments.

Combining Series Analysis with Candlesticks Charting Techniques

The BH and FT strategies have comparable dispersions for the analyzed indices. These strategies are, however, very different. This is why the returns do not correlate strongly. It means that combining these two strategies is effective to reduce the dispersion.

In this Sect., we attempt to develop a computer-based strategy which is distinct from the previous ones. This strategy uses new technical tools. Due to this reason, we expect that its return does not correlate strongly with the BH and FT returns, so that by combining these strategies the dispersion can further be reduced.

The candlesticks charting techniques is believed to be useful for understanding the major market moves and its turning points [\cite=Nison]. It is the most useful when it is supplemented with general analysis of the market. The series analysis which we discussed in the previous Sects. provides useful hints in this respect. Long series e.g. result into overbought or oversold states, in which the candlesticks patterns work differently. We perform a backtest of the candlesticks patterns separately for the up- and down-series of each length. One can expect that combining the series analysis with the candlesticks techniques can improve the record of the single methods.

Use and misuse of computer backtesting

Backtesting means the following: Suppose we have a well fixed strategy, i.e. a fixed set of prescriptions when to buy and sell an index. If we have historical quotes, the performance of the strategy can be tested. Such a procedure is called backtesting. It gives an idea on the possible future performance.

We make distinction between causal backtesting and non-causal backtesting. To explain the difference, consider an example: Let we work with a moving average which has just one free parameter, the number of days to be averaged. This parameter can be treated as a fitting parameter. It can be determined by requiring that the return during the backtested period be the greatest one.

The return obtained this way is, however, not the one to be expected from the future performance. Since the fitted parameter depends on the whole backtested set of the historical quotes, the return e.g. in the year 1975 depends e.g. on the year 1995, in the apparent contradiction with the causality. The non-causal backtesting gives an idea on the reasonable values of the fitting parameters, but the return is always overestimated. The example described above illustrates the possible misuse of the computer backtesting.

Causal backtesting means the following: In the year 1975, we calculate from the historical quotes an optimal value of the days for a moving average. Using this optimal value, we calculate then the return in the year 1976. After that, we calculate an optimal value of the days by adding the year 1976 to the set of the historical quotes, which we used earlier to fix the fitting parameter. This new optimal value is used to calculate the return in the year 1977. The procedure is repeated every year. The total return is a sum of the returns calculated for all the years. Such a calculation is essentially equivalent to a real-time testing. The causality, clearly, is not violated, since the calculated return e.g. in the year 1977 depends on the historical quotes from the previous years only. The return from the causal backtesting gives more realistic idea on the future performance. It is always lower than the return form the non-causal backtesting. In what follows, we speak on the causal backtesting only.

Analytic images of candlesticks charting patterns for computers

The characteristic candlesticks patterns are described in the literature in an intuitive fashion [\cite=Nison]. In order to implement the candlesticks charting techniques into a computer code, one needs to formulate in a language clear for every programmer how to distinguish the special informative patterns from the common ones. We include into our code about 30 analytic images which correspond to about 20 typical candlesticks patterns. Since clear prescriptions on how to construct the analytic images do not exist, several analytic images are usually probed. The code by analyzing the past performance decides which analytic images work better.

Example 1: The one-line "hammer" pattern is expected to be bullish in the downtrend. This pattern does work in down-series. Several analytic images can be proposed to distinguish the hammer pattern:

[formula]

where H, L, O, C are the high, low, open, and close of the index. For the hammer pattern, the value of ξ is large positive. The code uses this signature to recognize the hammer pattern between the others. How large ξ should be is decided by computer from the analysis of the historical performance of the considered image. The critical value of ξ depends on the length of the down-series in which the bullish pattern appears.

Example 2: Two-line candlesticks pattern "bullish engulfing lines". The following analytic image can be proposed

[formula]

if [formula] and ξ = 0 otherwise. Here, [formula] and [formula] are the close and open of the analyzed index from the previous day. The values of ξ should be large when the bullish engulfing lines pattern is formed. How large the value of ξ should be is decided by the computer from analysis of the past pattern performance. The critical value of ξ are different for the down-series of the different lengths, in which the bullish pattern appears.

The similar formulae can also be written for other patterns. Notice again that there is no a unique prescription how to construct the analytic images. The similar situation exists in the mathematical statistics where the so-called "statistics", which play an important role in the decision theory, are not uniquely defined. Nevertheless, they are widely used in the data analysis (see e.g. [\cite=Wilks] [\cite=Portenko] [\cite=Krivoruchenko] and references therein).

The analytic images work in the code as follows: We consider the first 5 to 10 years of the historical quotes to fix confidence intervals for the analytic images. We list and keep information on the all up- and down-series of a fixed length. For each series and each pattern, a distribution function of ξ is constructed. We compare the number of points in the confidence interval ξ∈( -   ∞  ,a) which are accompanied by continuation and reversal of the series. The value of a is varied. We are looking for those values of a which give the best chance of the continuation or the reversal of the series. We pay attention to an image if and only if the confidence interval provides a chance better than 3:1 (win-to-loss ratio). There are many confidence intervals providing such chances and containing many data points. The win-to-loss ratio at this stage refers, however, to the non-causal backtesting. It should be overestimated, as we discussed above. Indeed, the causal backtesting of the years, following the first ones, shows that the actual win-to-loss (W/L) ratio is about 4:3, as shown in Tables 7 - 10. The confidence intervals ξ∈(b, +   ∞  ) are constructed in the same way and the common results are the similar.

The backtest results reported in Tables 7, 8, 9, and 10 for the computer-based strategy are mixed at present. There are extended time periods in the S&P and NYSE indices where the computer-based strategy worked well. Nasdaq gives also good record. There are periods at DJIA, S&P, and NYSE indices, however, where the records are quite poor. The available code will be improved.

Conclusion

In this paper, a statistical analysis of the major USA market indices DJIA, S&P, Nasdaq, and NYSE is made. We verified that the market behavior is very close to the stochastic one and that the market dynamics is quite similar to the random walking.

The Markov chains approach was applied to study two-step correlations in the daily, weekly, and monthly historical quotes. The correlation parameters are determined empirically. The correlations are found to be statistically significant for the daily quotes, whereas the weekly and monthly quotes do not display clear effect.

There are deviations from the geometrical distribution of the number of series of the fixed length. The empirical probabilities are collected in Tables 3, 4, and 5. There are exceptional deviations: Nasdaq during the years 1985 - 2000 did not fall off more than 6 weeks in raw in the weekly quotes and more than 4 month in raw in the monthly quotes.

We calculated the return and the dispersion of the buy-and-hold and follow-trend strategies. These strategies are combined to decrease the dispersion. The optimal ratio between investments into these two strategies, providing a minimal risk, is found analytically.

The weekly and monthly correlation parameters are calculated in terms of the daily parameters. The results show reasonable agreement with the empirical data for the weekly quotes. There are, however, evident deviations in the monthly quotes for the down-series. The empirical probabilities for continuation of the down-trend are noticeably greater than the calculated probabilities (Parkinson Law?). It can be interpreted to mean that the large-scale market dynamics is not fully determined by the short-scale dynamics.

It was shown that the correlation parameters at different scales obey the renorm group equations.

This work reported also the intermediate results of the constructing a computer-based strategy that combines the series analysis with the candlesticks charting techniques.

The results of the statistical analysis of the historical quotes for the four major USA market indices DJIA, S&P, Nasdaq, and NYSE are reported from the permission of Commodity Systems, Inc. (CSI), the copyright owner of these quotes (web-site http://www.csidata.com). The author wishes to thank also the Dow Jones Indexes, the owner of the Dow Jones Industrial Average, for providing him with the DJIA historical quotes and the permission to use these quotes for the present publication. The author is grateful to European Physical Society for a grant which made possible his participation at the Conference "Application of Physics in Financial Analysis" (5 - 7 December 2001, London). The author is indebted to the Institute for Theoretical Physics of University of Tuebingen for kind hospitality and providing an opportunity to bring this paper into the final form.