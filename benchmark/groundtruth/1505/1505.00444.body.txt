hyperref

Some Theoretical Properties of a Network of Discretely Firing Neurons

This paper was submitted to Special Issue of Neurocomputing on Theoretical Analysis of Real-Valued Function Classes on 19 January 1998. It was not accepted for publication, but it underpins several subsequently published papers.

Abstract: The problem of optimising a network of discretely firing neurons is addressed. An objective function is introduced which measures the average number of bits that are needed for the network to encode its state. When this is minimised, it is shown that this leads to a number of results, such as topographic mappings, piecewise linear dependence on the input of the probability of a neuron firing, and factorial encoder networks.

Introduction

In this paper the problem of optimising the firing characteristics of a network of discretely firing neurons will be considered. The approach adopted will not be based on any particular model of how real neurons operate, but will focus on theoretically analysing some of the information processing capabilities of a layered network of units (which happen to be called neurons). Ideal network behaviour is derived by choosing the ideal neural properties that minimise an information theoretic objective function which specifies the number of bits required by the network to encode the state of its layers. This is done in preference to assuming a highly specific neural behaviour at the outset, followed by optimisation of a few remaining parameters such as weight and bias values.

Why use an objective function in the first place? An objective function is a very convenient starting point (a set of "axioms", as it were), from which everything else can, in principle, be derived (as "theorems", as it were). An objective function has the same status as a model, which may be falsified should some counterevidence be discovered. The objective function used in this paper is the simplest that is consistent with predicting a number of non-trivial results, such as topographic mappings, and factorial encoders (which are discussed in this paper). However, it does not include any temporal information, nor any biological plausibility constraints (other than the fact that the network is assumed to be layered). More complicated objective functions will be the subject of future publications.

In section [\ref=sec:Theory] an objective function is introduced, and its connection with discretely firing neural networks is derived. In section [\ref=sec:Examples] some examples are presented which show how this theory of discretely firing neural networks leads to some non-trivial results.

Theory

In this section a theory of discretely firing neural networks is developed. Section [\ref=sub:Objective-Function-for] introduces the objective function for optimising an encoder, and section [\ref=sub:Application-to-Neural] shows how this can be applied to the problem of optimising a discretely firing neural network.

Objective Function for Optimal Coding

The inspiration for the approach that is used here is the minimum description length (MDL) method [\cite=Rissanen1978]. In this paper, a training set vector (which is unlabelled) will be denoted as [formula], a vector of statistics which are stochastically derived from [formula] will be denoted as [formula], and their joint probability density function (PDF) will be denoted as [formula]. The problem is to learn the functional form of [formula], so that vectors [formula] sampled from [formula] can be encoded using the minimum number of bits on average. It is unconventional to consider the problem of encoding [formula], rather than [formula] alone, but it turns out that this leads to many useful results.

Thus [formula] is approximated by a learnt model [formula], in which case the average number of bits required to encode an [formula] sampled from the PDF [formula] is given by the objective function D, which is defined as

[formula]

Now split D into two contributions by using [formula] and [formula].

[formula]

The first term is the cost (i.e. the average number of bits), averaged over all possible values of [formula], of encoding an [formula] sampled from [formula] using the model [formula]. This interpretation uses that [formula]. The second term is the cost of encoding a [formula] sampled from [formula] using the model [formula]. Together these two terms correspond to encoding [formula] (the second term), then encoding [formula] given that [formula] is known.

The model [formula] may be optimised so that it minimises D, and thus leads to the minimum cost of encoding [formula] sampled from [formula]. Ideally [formula], but in practice this is not possible because insufficient information is available to determine [formula] exactly (i.e. the training set does not contain an infinite number of [formula] vectors). It is therefore necessary to introduce a parametric model [formula], and to choose the values of the parameters so that D is minimised. If the number of parameters is small enough, and the training set is large enough, then the parameter values can be accurately determined.

A further simplification may be made if [formula] can occupy much fewer states than [formula] (given [formula]) can, because then the cost of encoding [formula] is much less than the cost of encoding [formula] (given [formula]) (i.e. the second and first terms in equation [\ref=eq:ObjectiveSplit], respectively). In this case, it is a good approximation to retain only the first term in equation [\ref=eq:ObjectiveSplit]. This approximation becomes exact if [formula] assigns equal probability to all states [formula], because then the third term is a constant. The reason for defining the objective function D as in equation [\ref=eq:Objective], rather than defining it to be the first term of equation [\ref=eq:ObjectiveSplit], is because equation [\ref=eq:Objective] may be readily generalised to more complex systems, such as [formula] in which [formula], and so on. An example of this is given in section [\ref=sub:Topographic-Mapping-Neural].

It is possible to relate the minimisation of D to the maximisation of the mutual information I between [formula] and [formula]. If the cost of encoding an [formula] sampled from [formula] using the model [formula] (i.e. [formula]) and the cost of encoding a [formula] sampled from [formula] using the model [formula] (i.e. [formula]) are both subtracted from D, then the result is [formula]. When [formula] this reduces to (minus) the mutual information I between [formula] and [formula]. Thus, if the cost of encoding the correlations between [formula] and [formula] is much greater than the cost of separately encoding [formula] and [formula] (i.e. the [formula] term can be ignored in I), then D-minimisation approximates I-maximisation, which is another commonly used objective function.

Application to Neural Networks

In order to apply the above coding theory results to a 2-layer discretely firing neural network, it is necessary to interpret [formula] as a pattern of activity in the input layer, and [formula] as the vector of locations in the output layer of a finite number of firing events. The objective function D is then the cost of using the model [formula] of the network behaviour to encode the state [formula] of the neural network (i.e. the input pattern and the location of the firing events), which is sampled from the [formula] that describes the true network behaviour. For instance, a second neural network can be used solely for computing the model [formula], which is then used to encode the state [formula] of the above first neural network. Note that no temporal information is included in this analysis, so the input and output of the network is a static [formula] vector containing no time variables.

These two neural networks can be combined into a single hybrid network, in which the machinery for computing the model [formula] is interleaved with the neural network, whose true behavior is described by [formula]. The notation of equation [\ref=eq:ObjectiveSplit] can now be expressed in more neural terms, where [formula] is then a recognition model (i.e. bottom-up) and [formula] is then a generative model (i.e. top-down), both of which live inside the same neural network. This is an unsupervised neural network, because it is trained with examples of only [formula]-vectors, and the network uses its [formula] to stochastically generate a [formula] from each [formula].

Now introduce a Gaussian parametric model [formula]

[formula]

where [formula] is the centroid of the Gaussian (given [formula]), σ is the standard deviation of the Gaussian. Also define a soft vector quantiser (VQ) objective function [formula] as

[formula]

which is (twice) the average Euclidean reconstruction error that results when [formula] is probabilistically encoded as [formula] and then deterministically reconstructed as [formula]. These definitions of [formula] and [formula] allow D to be written as

[formula]

where the second term is constant, and the third term may be ignored if [formula] can occupy much fewer states than [formula] (given [formula]) can. The conditions under which the third term can be ignored are satisfed in a neural network, because [formula] is an activity pattern, and [formula] as the vector of locations of a finite number of firing events.

The first term of D is proportional to [formula], whose properties may be investigated using the techniques in [\cite=Luttrell1997]. Assume that there are n firing events, so that [formula], then the marginal probabilities of the symmetric part [formula] of [formula] under interchange of its [formula] arguments are given by

[formula]

where [formula] may be interpreted as the probability that the next firing event occurs on neuron y (given [formula]), Also define 2 useful integrals, D1 and D2, as

[formula]

where [formula] is any vector function of y (i.e. not necessarily related to [formula]), to yield the following upper bound on [formula]

[formula]

where D1 is non-negative but D2 can have either sign, and the inequality reduces to an equality in the case n = 1. Thus far nothing specific has been assumed about [formula], other than the fact that it contains no temporal information, so the upper bound on [formula] applies whatever the form of [formula].

If the firing events occur independently of each other (given [formula]), then [formula], which allows D2 to be redefined as

[formula]

where D2 is non-negative.

In summary, the assumptions which have been made in order to obtain the upper bound on [formula] in equation [\ref=eq:ObjectiveD1D2] with the definition of D1 as given in equation [\ref=eq:CorrelatedD1D2] and D2 as given in equation [\ref=eq:IndependentD2] are: no temporal information is included in the network state vector [formula], [formula] can occupy much fewer states than [formula] (given [formula]) can, and firing events occur independently of each other (given [formula]). In reality, there is always temporal information available, and the firing events are correlated with each other, so a more realistic objective function could be constructed. However, it is worthwhile to consider the consequences of equation [\ref=eq:ObjectiveD1D2], because it turns out that it leads to many non-trivial results.

The upper bound on [formula] may be minimised with respect to all free parameters in order to obtain a least upper bound. In the case of independent firing events, the free parameters are the [formula] and the [formula]. These two types of parameters cannot be independently optimised, because they correspond to the generative and recognition models implicit in the neural network, respectively.

A gradient descent algorithm for optimising the parameter values may readily be obtained by differentiating D1 and D2 with respect to [formula] and [formula]. Given the freedom to explore the entire space of functions [formula], the optimum neural firing behaviour (given [formula]) can in principle be determined, and in certain simple cases this can be determined by inspection. If this option is not available, such as would be the case if biological contraints restricted the allowed functional form of [formula], then a limited search of the entire space of functions [formula] can be made by invoking parametric model of the neural firing behaviour (given [formula]).

Examples

In this section several examples are presented which illustrate the use of D1 + D2 in the optimisation of discretely firing neural networks. In section [\ref=sub:Topographic-Mapping-Neural] a topographic mapping network is derived from D1 alone, in section [\ref=sub:Piecewise-Linear-Probability] [formula] that minimises D1 + D2 is shown to be piecewise linear, and a solved example is presented. Finally, in section [\ref=sub:Factorial-Encoder-Network] a more detailed worked example is presented, which demonstrates how a factorial encoder emerges when D1 + D2 is minimised.

Topographic Mapping Neural Network

When an appropriate from of [formula] is considered, it can be seen that it leads to a network that is closely related to Kohonen's topographic mapping network [\cite=Kohonen1989].

The derivation of a topographic mapping network that was given in [\cite=Luttrell1989b] will now be recast in the framework of section [\ref=sub:Application-to-Neural]. Thus, consider the objective function for a 3-layer network [formula], in which (compare equation [\ref=eq:Objective])

[formula]

where the cost of encoding y has been ignored, so that effectively only a 2-layer network [formula] is visible, and [formula] is given by

[formula]

This expression for [formula] explicitly involves [formula], but it may be manipulated into a form that explicitly involves [formula]. In order to make simplify this calculation, [formula] will be replaced by the equivalent objective function

[formula]

Now introduce dummy integrations over y to obtain

[formula]

and rearrange to obtain

[formula]

where

[formula]

which may be replaced by the equivalent objective function

[formula]

By manipulating [formula] from the form it has in equation [\ref=eq:ObjectiveLayer12] to the form it has in equation [\ref=eq:ObjectiveLayer01], it becomes clear that optimisation of the [formula] network involves optimisation of the [formula] subnetwork, for which an objective function can be written that uses a [formula] as defined in equation [\ref=eq:LeakedPosterior]. When optimising the [formula] subnetwork, [formula] takes account of the effect that z has on y.

If n = 1, so that only 1 firing event is observed, then [formula], and the optimum [formula] must ensure that y depends deterministically on [formula], so that [formula] where [formula] is an encoding function that converts [formula] into the index of the neuron that fires in response to [formula]. This allows [formula] to be simplified to

[formula]

where [formula] is [formula] with y replaced by [formula]. Note that if [formula] then [formula] reduces to the objective function [formula] for a standard vector quantiser (VQ).

The optimum [formula] is given by [formula] (which is not quite the same as the [formula] used by Kohonen in his topographic mapping neural network [\cite=Kohonen1989]), and a gradient descent algorithm for updating [formula] is [formula] (which is identical to Kohonen's prescription [\cite=Kohonen1989]). The [formula] may thus be interpreted as the neighbourhood function, and the [formula] may be interpreted as the weight vectors, of a topographic mapping. Because all states y that can give rise to the same state z (as specified by Pr (z|y)) become neighbours (as specified by [formula] in equation [\ref=eq:LeakedPosterior]), [formula] includes a much larger class of neighbourhood functions than has hitherto been used in topographic mapping neural networks.

Because of the principled way in which the topographic mapping objective function has been derived here, it is the preferred way to optimise topographic mapping networks. It also allows the objective function to be generalised to the case n > 1, where more than one firing event is observed.

Piecewise Linear Probability of Firing

The optimal [formula] has some interesting properties that can be obtained by inspecting its stationarity condition. For instance, the [formula] that minimise D1 + D2 will be shown to be piecewise linear functions of [formula].

Thus, functionally differentiate D1 + D2 with respect to [formula], where logarithmic differentation implicitly imposes the constraint [formula], and use a Lagrange multiplier term [formula] to impose the normalisation constraint [formula] for each [formula], to obtain

[formula]

The stationarity condition implies that [formula], which may be used to determine the Lagrange multiplier function [formula]. When [formula] is substituted back into the stationarity condition itself, it yields

[formula]

There are several classes of solution to this stationarity condition, corresponding to one (or more) of the three factors in equation [\ref=eq:StationarityP] being zero.

[formula] (the first factor is zero). If the input PDF is zero at [formula], then nothing can be deduced about [formula], because there is no training data to explore the network's behaviour at this point.

[formula] (the second factor is zero). This factor arises from the differentiation with respect to [formula], and it ensures that [formula] cannot be attained. The singularity in [formula] when [formula] is what causes this solution to emerge.

[formula] (the third factor is zero). The solution to this equation is a [formula] that has a piecewise linear dependence on [formula]. This result can be seen to be intuitively reasonable because D1 + D2 is of the form [formula], where [formula] is a linear combination of terms of the form [formula] (for i = 0,1,2 and j = 0,1,2), which is a quadratic form in [formula] (ignoring the [formula]-dependence of [formula]). However, the terms that appear in this linear combination are such that a [formula] that is a piecewise linear function of [formula] guarantees that [formula] is a piecewise linear combination of terms of the form [formula] (for i = 0,1,2), which is a quadratic form in [formula] (the normalisation constraint [formula] is used to remove a contribution to that is potentially quartic in [formula]). Thus a piecewise linear dependence of [formula] on [formula] does not lead to any dependencies on [formula] that are not already explicitly present in D1 + D2. The stationarity condition on [formula] (see equation [\ref=eq:StationarityP]) then imposes conditions on the allowed piecewise linearities that [formula] can have.

For the purpose of doing analytic calculations, it is much easier to obtain analytic results with the ideal piecewise linear [formula] than with some other functional form. If the optimisation of [formula] is constrained, by introducing a parametric form which has some biological plausibility, for instance, then analytic optimum solutions are not in general possible to calculate, and it becomes necessary to resort to numerical simulations. Piecewise linear [formula] should therefore be regarded as a convenient theoretical laboratory for investigating the properties of idealised neural networks.

Solved Example

A simple example illustrates how the piecewise linearity property of [formula] may be used to find optimal solutions. Thus consider a 1-dimensional input coordinate x∈[ -      ∞   ,  +     ∞ ], with Pr (x) = P0. Assume that the number of neurons M tends to infinity in such a way that there is 1 neuron per unit length of x, so that Pr (y|x) = p(y - x), where the piecewise linear property gives p(x) as

[formula]

and by symmetry [formula].

This Pr (y|x) and [formula] allow D1 to be derived as

[formula]

and D2 to be derived as

[formula]

Because there is one neuron per unit length, the contribution per unit length to D1 + D2 is the sum of the above two results

[formula]

If D1 + D2 is differentiated with respect to s, then stationarity condition [formula] yields the optimum value of s as

[formula]

and the stationary value of D1 + D2 as

[formula]

When n = 1 the stationary solution reduces to s = 0 and D1 + D2 (per unit length) [formula], which is a standard vector quantiser with nonoverlapping neural response regions which partition the input space into unit width quantisation cells, so that for all x there is exactly one neuron that responds. Although the neurons have been manually arranged in topographic order by imposing Pr (y|x) = p(y - x), any permutation of the neuron indices in this stationary solution will also be stationary solution. This derivation could be generalised to the type of 3-layer network that was considered in section [\ref=sub:Topographic-Mapping-Neural] , in which case a neighbourhod function [formula] would emerge automatically.

As n  →    ∞   the stationary solution behaves as [formula] and D1 + D2 (per unit length) [formula], with overlapping linear neural response regions which cover the input space, so that for all x there are exactly two neurons that respond with equal and opposite linear dependence on x. As n  →    ∞   the ratio of the number of firing events that occur on these two neurons is sufficient to determine x to [formula]. When n =   ∞   this stationary solution is [formula] and D1 + D2 (per unit length) = 0. However, when n =   ∞   there are infinitely many other ways in which the neurons could be used to yield D1 + D2 (per unit length) = 0, because only the D2 term contributes, and it is 0 when [formula]. This is possible for any set of basis elements [formula] that span the input space, provided that the expansion coefficients Pr (y|x) satisfy [formula]. In this 1-dimensional example only two basis elements are required (i.e. M = 2), which are [formula] and [formula]. More generally, for this type of stationary solution, [formula] is required to span the input space in such a way that [formula], and if [formula] then the stationary solution will span the input subspace (of dimension M - 1) that has the largest variance.

The n = 1 and n  →    ∞   limiting cases are very different. When n = 1 the optimum network splits up the input space into non-overlapping quantisation cells, and as n  →    ∞   the optimum network does a linear decomposition of the input space using non-negative expansion coefficients. This behaviour occurs because for n > 1 the neurons can cooperate when encoding the input x, so that by allowing more than one neuron to fire in response to x, the encoded version of x is distributed over more than one neuron. In the above 1-dimensional example, the code is spread over one or two neurons depending on the value of x. This cooperation amongst neurons is a property of the coherent part D2 of the upper bound on [formula] (see equation [\ref=eq:ObjectiveD1D2]).

Factorial Encoder Network

For certain types of distribution of data in input space the optimal network consists of a number of subnetworks, each of which responds to only a subspace of the input space. This is called factorial encoding, where the encoded input is distributed over more than one neuron, and this distributed code typically has a much richer structure than was encountered in section [\ref=sub:Piecewise-Linear-Probability].

The simplest problem that demonstrates factorial encoding will now be investigated (this example was presented in [\cite=Luttrell1997b], but the derivation given here is more direct). Thus, assume that the data in input space uniformly populates the surface of a 2-torus S1  ×  S1. Each of the S1 is a plane unit circle embedded in R1  ×  R1 and centred on the origin, and S1  ×  S1 is the Cartesian product of a pair of such circles. Overall, the 2-torus lives in a 4-dimensional input space whose elements are denoted as [formula], where one of the circles lives in (x1,x2) and the other lives in (x3,x4). These circles may be parameterised by angular degrees of freedom θ12 and θ34, respectively.

The optimal [formula] (i.e. a piecewise linear stationary solution of the type that was encountered in section [\ref=sub:Piecewise-Linear-Probability] could be derived from this input data PDF [formula]. However, the properties of the sought-after optimal [formula] are preserved if one restricts the solution space to the following types of [formula]

[formula]

where y(θ12) and y12(θ12) encode θ12, y(θ34) and y34(θ34) encode θ34, and y(θ12,θ34) encodes (θ12,θ34). The allowed ranges of the code indices are 1  ≤  y(θ12)  ≤  M (and similarly y(θ34)), [formula], [formula], and 1  ≤  y(θ12,θ34)  ≤  M. The type 1 solution assumes that all M neurons respond only to θ12 (or, alternatively, all respond only to θ34), the type 2 solution assumes that all M neurons respond to (θ12,θ34), and the type 3 solution (which is very simple type of factorial encoder) assumes that [formula] neurons respond only to θ12, and the other [formula] neurons respond only to θ34.

In order to derive explicit results for the stationary value of D1 + D2, it is necessary to optimise the [formula]. The stationary condition on [formula] may readily be deduced from the stationarity condition [formula] as

[formula]

If [formula] (and hence [formula]) are inserted into this stationarity condition, then it may be solved for the corresponding [formula].

Assume that the encoding functions partition up the 2-torus symmetrically, the three types of solution may be optimised as described in the following three sections.

Type 1 Solution

Assume that [formula], and that the y = 1 quantisation cell is the Cartesian product of the arcs [formula] and [formula] of the 2 unit circles that form the 2-torus, then the stationarity condition for [formula] becomes

[formula]

which yields the solution [formula]. The first two components are the centroid of the arc [formula] of a unit circle centred on the origin. All of the [formula] can be obtained by rotating [formula] about the origin by multiples of [formula]. Using the assumed symmetry of the solution, the expression for D1 + D2 becomes

[formula]

where the first (or second) term corresponds to the subspace to which the neurons respond (or not respond). This gives the stationary value of D1 + D2 as [formula]. Only one neuron can fire (given [formula]), because [formula] or δy,y(θ34), no further information about [formula] can be obtained after the first firing event has occurred, so this result for D1 + D2 is independent of n, as expected.

Type 2 Solution

Assume that the y = 1 quantisation cell is the Cartesian product of the arcs [formula] and [formula] of the two unit circles that form the 2-torus. The stationarity condition for [formula] can be deduced from the type 1 case with the replacement [formula], which gives [formula]. The expression for D1 + D2 may similarly be deduced from the type 1 case as twice the first term in equation [\ref=eq:D1D2Type1] with the replacement [formula], to yield the stationary value of D1 + D2 as [formula]. As in the type 1 case, this result for D1 + D2 is independent of n.

Type 3 Solution

The stationarity condition for [formula] can be written by analogy with the type 1 case, with the replacement [formula], and modifying the last term to take account of the more complicated form of [formula], to yield

[formula]

where [formula] has been used (this follows from the assumed symmetry of the solution). This yields the solution [formula]. Using the assumed symmetry of the solution, the expression for D1 becomes

[formula]

and the expression for D2 becomes

[formula]

This gives the stationary value of D1 + D2 as [formula]. Because [formula], one firing event has to occur in each of the intervals [formula] and [formula] for all of the information to be collected about [formula]. However, the random nature of the firing events means that the probability with which this condition is satisfied increases with n, so this result for D1 + D2 decreases as n increases.

Relative Stability of Solutions

Collect the above results together for comparison.

[formula]

For constant M and letting n  →    ∞  , the value of D1 + D2 for the type 3 solution asymptotically behaves as [formula], in which case the relative stability of the three types of solution is: type 3 (most stable), type 2 (intermediate), type 1 (least stable). Similarly, for constant n and letting M  →    ∞  , the relative stability of the three types of solution is: type 2 (most stable), type 3 (intermediate), type 1 (least stable).

In both of these limiting cases the type 1 solution is least stable. If there is a fixed number of firing events n, and there is no upper limit on the number of neurons M, then the type 2 solution is most stable, because it can partition the 2-torus into lots of small quantisation cells. If there is a fixed number of neurons M (which is the usual case), and there is no upper limit on the number of firing events n, then the type 3 solution is most stable, because the limited size of M renders the type 2 solution inefficient (the quantisation cells would be too large), so the 2-torus S1  ×  S1 is split into two S1 subspaces each of which is assigned a subset of [formula] neurons. If n is large enough, then each of these two subsets of neurons has a high probability of occurrence of a firing event, which ensures that both of the S1 subspaces are encoded.

More generally, when there is a limited number of neurons they will tend to split into subsets, each of which encodes a separate subspace of the input. The assumed form of [formula] in equation [\ref=eq:SolutionTypes] does not allow an unrestricted search of all possible [formula]. If the global optimum solution (which has piecewise linear [formula], as proved in section [\ref=sub:Piecewise-Linear-Probability]) cuts up the input space into partially overlapping pieces, then it is well approximated by a solution such as one of those listed in equation [\ref=eq:SolutionTypes]. Typically, curved input spaces lead to such solutions, because a piecewise linear [formula] can readily quantise such spaces by slicing off the curved "corners"' that occur in such spaces.

Conclusions

In this paper an objective function for optimising a layered network of discretely firing neurons has been presented, and three non-trivial examples of how it is applied have been shown: topographic mapping networks, piecewise linear dependence on the input of the probability of a neuron firing, and factorial encoder networks. Many other examples could be given, such as combining the first and third of the above results to obtain factorial topographic networks, or extending the theory to multilayer networks, or introducing temporal information.

Acknowledgements

I thank Chris Webber for many useful conversations that we had during the course of this research.