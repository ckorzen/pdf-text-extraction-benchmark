Lemma Corollary Definition

One Packet Suffices - Highly Efficient Packetized Network Coding With Finite Memory

Introduction

Random linear network coding (RLNC) has been shown to robustly achieve network capacity in multicast scenarios [\cite=ho2006random]. It is asymptotically optimal rate-wise even in the presence of erasures when the erasures are globally known [\cite=dana2006capacity] or not [\cite=lun2008coding] [\cite=lun2005further]. For distributed packet networks with unknown or changing topologies a packetized RLNC protocol was suggested [\cite=chou2003practical] [\cite=lun2008coding]. This RLNC protocol has been intensely studied, mostly under the name of algebraic gossip [\cite=algebraicgossip-deb-medard04-allerton] [\cite=informationdissemination05] [\cite=borokhovich2010tight] [\cite=mosk2006information] [\cite=haeupler-karger11]. Recently, this line of work cumulated in the introduction of projection analysis [\cite=haeupler2010analyzing], a general technique that provides tight optimal bounds for all network models considered up to this point. None of the above works takes into account the memory required at nodes that participate in the dissemination with no intent on collecting all data. They also do not consider the size of the data upon which coding takes place. While this has been identified as an important problem, the solutions offered so far [\cite=lun2006analysis] [\cite=sundararajan2007queueing] [\cite=sundararajan2008arq] [\cite=bhadra2007looking] are very restricted.

In this paper we consider network coding with very limited active memory. We show the surprising result that, in all settings with a continuous stream of data, network coding continues to perform optimally even if only one packet per node is kept in active memory. We introduce two extremely simple and efficient RLNC variants that use only minimal memory and computational resources. By extending the projection analysis, we give a general technique to obtain tight performance guarantees on these variants. In the same way as the projection analysis our technique applies in a wide variety of network and communication models including highly dynamic topologies that change completely at every time in an adversarial fashion. In all these settings the (order) optimal performance guarantees we obtain for the new protocols matches the best guarantees known for the full-blown RLNC protocol. We provide examples for relaxations of classical expansion parameters like isoperimetry that give tighter capacity characterizations for (these) dynamic networks.

Related Work

In this section we summarize related work that addresses the question of reducing coding buffer sizes:

The impact of finite memory was first considered in [\cite=lun2006analysis]. The paper takes a fairly involved Markov chain approach to model the evolution of the degrees of freedom at a single intermediate node. Its analysis is restricted to communication along a simple path and the field size, q, is assumed to be unbounded, which evades the question of likelihood of an unhelpful transmission. In general networks [\cite=lun2008coding] and [\cite=borokhovich2010tight] use queuing approaches of the Jackson Networks type but their analysis track degrees of freedom rather than actual packets and does not explicitly consider memory. References [\cite=sundararajan2007queueing] [\cite=sundararajan2008arq] show that it suffices for a node to keep only the coset space of the intersection of the data received at the node and of all the spaces representing the data received by its neighbors. However, that work requires feedback and establishes sufficiency of the coset space, not necessity. Moreover, the coset space is in many cases of the same order as the entire space we seek to transmit and the results do not hold under variable network topologies, which would lead to variable coset spaces. The use of network coding for spatial buffer multiplexing in multi-hop networks is considered in [\cite=bhadra2007looking]. It analyzes large networks with reduced size packet buffers and shows that asymptotically the network acts as a shared buffer if the length of flow paths and the number of flows through each node are both polynomially large.

Multicast in Dynamic Networks

In this section we briefly review the many-to-many multicast problem and the dynamic network model considered in this paper. We refer to [\cite=haeupler2010analyzing] for an extensive discussion of the generality of the approach taken here, the various network and communication models it applies to and how these models encompass and generalize models given in prior literature.

The many-to-many multicast problem is a typical distributed information dissemination problem. Some information is known to a subset of nodes in a network and through communicating with each other all nodes (or a different subset of recipients) are supposed to learn about all information. In many modern networks like P2P-networks, or (wireless) ad-hoc meshes protocols have to deal with unknown, highly unstable or dynamic network topologies. We formalize this by assuming a dynamic network consisting of n nodes. The topology for every time t is specified by a graph G(t) which is chosen by a fully adaptive adversary that knows the complete network state including which node knows what. For simplicity we assume that the adversary decides on a topology before the nodes (randomly) generate their packets for the current round. This requirement can be dropped [\cite=haeupler-karger11]. Nodes have no knowledge of the topology and decide on a packet to send. Whether a packet gets delivered to the neighbor(s) of a node depends on the communication model. At time t = 0 the adversary distributes k messages each to at least one node. We assume that the messages [formula] are l dimensional vectors over a finite field Fq, where q is a sufficiently large prime or prime power. We are interested in analyzing the stopping time of a protocol, i.e., the expected time until all recipients know all messages. All our results hold with exponentially high probability.

The RLNC Protocols

In this section we review RLNC, the packetized network coding protocol [\cite=chou2003practical] [\cite=lun2008coding], and introduce two variants that use only a finite amount of active memory: the accumulator FM-RLNC (from [\cite=lun2006analysis]) and the recombinator FM-RLNC.

Every packet used by the protocols has the form [formula], where [formula] is a linear combination of the messages, and [formula] is the vector of the coefficients. Each node u keeps a set of active packets. If a node u knows message mi initially we assume (ei,mi) to be an active packet of u, here ei is the ith unit vector in [formula]. Whenever a node u is supposed to send out a packet, it chooses a random vector from the span of its active packets. Every node that is interested in decoding keeps all received packets until their coefficient vectors span the full space [formula]. Gaussian elimination can then be used to reconstruct all messages. The protocols solely differ in what packets are kept active. In the regular RLNC protocol each node v has unlimited memory and simply keeps all received packets active. The FM-RLNC variants, on the other hand, only keep s active packets. Therefore, whenever a new packet is received it is not stored but simply combined with the s stored packets. We introduce two possible ways of doing so. The accumulator FM-RLNC scheme adds random linear combinations of the incoming packets to the stored s active packets. The recombinator FM-RLNC scheme creates the new s packets as uniform random samples from the span of the stored and new packets. Note that for s = 1 both approaches are equivalent. Note also that the shift register scheme from [\cite=lun2006analysis] does in general not perform well in dynamic settings, which is why we do not consider it here.

Complexity Comparison

We briefly show the improved computational and memory complexity of the two FM-RLNC variants in comparison to the standard RLNC protocol.

The RLNC protocol described in Section [\ref=sec:alg] keeps all received packets in memory, even if they are already in the span of the stored packets. To avoid storing and frequently accessing these redundant packets it is often better to maintain the span of the received packets via a non-redundant basis. This is done by keeping only innovative packets, that increase the dimension of the span. This comes at the cost of an additional rank computation of a k  ×  k matrix for every received packet (which can be partially reused by storing an orthogonal basis instead). More importantly the RLNC protocol still requires each node to have k memory, enough to store all packets in the system. Even worse, at every time a packet is generated all k packets need to be accessed, which results in k cache-unfriendly IO-operations per sent packet.

The FM-RLNC protocols drastically reduce this complexity. Both require only space for s packets in their active memory and need only s (IO-)operations per packet sent out. Both protocols access the s packets for each received packet but differ slightly in their operations on these packets. While the recombinator requires O(s2) operations, the accumulator FM-RLNC protocol needs performs only one addition for each of the s packets. For s = O(1) this is a drastic reduction of the O(k) RLNC complexity. Beyond this, another important advantage of the FM-RLNC variants is that the number of active packets is so small that they can be entirely kept in fast (cache) memory. Using only a finite amount of memory and extremely simple arithmetic furthermore opens many possibilities to implement coding directly in hardware, e.g., in routers, switches or sensors.

Extending the Projection Analysis

In this section we show how the projection technique from [\cite=haeupler2010analyzing] can be extended to analyze the FM-RLNC protocols.

It is clear that every packet with coefficient vector [formula] also contains the linear combination of the messages specified by [formula]. Throughout the rest of this paper, we thus solely concentrate on the spreading of the coefficient vectors. The technique from [\cite=haeupler2010analyzing] can be understood as analyzing this spreading process by tracking qk projections of it; one along each direction in Fkq:

A node A knows about [formula] if its coefficient subspace of all its active packets is not orthogonal to [formula], i.e., if there it has an active packet with coefficient vector [formula] such that [formula].

Each such projection behaves like a 1 / q-faulty one-message flooding process:

If a node u knows about a vector [formula] and transmits a packet to node v then v knows about [formula] afterwards with probability at least 1  -  1 / q for the RLNC protocols and at least (1  -  1 / q)(1 - 1 / qs)  >  1  -  2 / q for both FM-RLNC protocols.

In the RLNC case, the spreading of knowledge for a vector [formula] is an easy to understand monotone increasing set growing process: It is a directed acyclic Markov chain with one absorbing state and its stopping probability therefore has an exponentially decaying tail. If T is the expected stopping time, i.e., the expected time for one message to flood then the probability that a fixed vector [formula] has not spread after t  =  T  +  k time is (usually) at most q- O(k). Taking a union bound over all vectors from [formula] implies that after t  =  O(T  +  k) time all nodes know all vectors and can decode.

Unfortunately, the spreading process of knowledge for a [formula] in the FM-RLNC protocols is not a monotone process anymore. Keeping only a small number of active packets makes many nodes "forget" vectors. The next lemma gives a formal definition and specifies the probability that this happens:

We say a node forgets a vector [formula] if it knows about it and after reception of a packet does not know about it anymore. The probability that a node forgets a fixed vector [formula] after receiving a packet is at most q- s if it keeps s active packets and runs the accumulator or recombinator FM-RLNC protocol.

Remark: Note that it is highly unlikely, but nevertheless possible, that a direction gets lost completely. While this probability is often negligible in practice, it can be completely avoided if the sources of the k messages keep the packets associated with these messages unchanged as active packets. This also avoids the possibility of a node with s < k active packets receiving more packets than it can store in the beginning. Therefore, throughout the rest of this paper, we use the assumption that no vector from [formula] gets completely forgotten.

Looking at the inverse dependence on q in Lemma [\ref=lem:forgetting] suggests a simple way to get around the problem of nodes forgetting a vector [formula], namely choosing q large enough. For example, if q is polynomial in both the running time of the protocol and n then a union bound shows that the probability that a vector [formula] gets ever forgotten is at most [formula]. Unfortunately, an inverse polynomially failure probability for each vector is not sufficient to finish the proof as before with a union bound over the exponentially many vectors in [formula]. Indeed, it is clear that for s < k a node has to forget many vectors to be able to learn others. Thus, instead proving as before that at some point each vector [formula] is known by all nodes we show that after a long enough time each vector knew [formula] (and then forgot it). This time at which a node knows a vector [formula] can in principle be different for every node. We prove the simpler but stronger statement that, for each [formula], there is with exponentially high probability one point in time at which all nodes know it. Even so the last step and the two union bounds seem very crude it turns out that, averaged over the exponentially many vectors, our bounds are spot on in the worst case and lead to simple proofs of (order) optimal convergence times.

The same is true for our choice of q. We first want to mention that choosing [formula] is a reasonable choice for the field size which leads to practical coefficients sizes that are logarithmic in n. Indeed, in all prior work [\cite=informationdissemination05] [\cite=borokhovich2010tight] [\cite=mosk2006information], except for [\cite=haeupler2010analyzing], coefficients of this size are required. Secondly we have a strong lower bound that logarithmic size coefficients are necessary if one wants to keep only finitely many active packets per node. The following lemma shows the sharp threshold result that even slightly sub-logarithmic coefficient sizes lead to exponentially long running times in adversarial dynamic networks. The lemma holds in all communication models in which nodes can only communicate with their neighbors and the proof also nicely demonstrates the power of an adaptive adversary:

For any q, with [formula], there is an adaptive adversary that chooses an always connected network (with diameter two at any time) on which the FM-RLNC protocol with s active packets takes, with high probability, at least en1 - o(1) time to succeed.

Our Results

Next, we use the analysis technique developed in the last section and demonstrate via several examples that essentially the same bounds as proven in [\cite=haeupler2010analyzing] for the RLNC protocol hold for the FM-RLNC protocols even with s = 1.

We start by giving results for the FM-RLNC protocol in the synchronous broadcast network model from [\cite=haeupler2010analyzing] [\cite=KLO]: At each time t, the adversary adaptively chooses the topology of the network as a (directed) graph G. Each node then creates a packet which is delivered to all its current neighbors.

The synchronous broadcast FM-RLNC protocol even with s = 1 takes with high probability at most [formula] time to spread k messages if the (directed) graph G is (strongly) l-vertex-connected at any point of time.

Note that, while both the example and the proof are very simple, any similar result has been elusive to obtain so far. Note also that the analysis is, up to constants, tight in the worst case, since the diameter of a l-vertex-connected graph can be [formula] and, if all messages start in one node v, it is also clear that at least k rounds are needed, since at each round only one packet is formed by v. The lemma thus shows, that FM-RLNC achieves an optimal, perfectly pipelined [\cite=haeupler2010analyzing] information spreading in always connected networks, even if only one packet is stored per node.

In the same manner, most proofs in [\cite=haeupler2010analyzing] can be extended to the FM-RLNC protocol. Next, we do this for Lemma 6.4 of [\cite=haeupler2010analyzing], that characterizes the stopping time for the synchronous broadcast model by its isoperimetric expansion, which is tight for most regular graphs. Emphasizing the applicability in a dynamic setting we show here that the proof does not just extend to the FM-RLNC setting but also to a much more flexible and weaker notion of isoperimetry for dynamic graphs which we introduce next:

For a graph G and a subset S let hG(S) be the union of S and the (directed) neighborhood of S, i.e., the nodes in [formula] that are reachable from S via directed or undirected edges. The isoperimetric number of G is defined as [formula]. Building on this we say a dynamic graph G(t) has a relaxed isoperimetric number H(G) if there exists a constant Δ such that for every non-empty subset S  ⊆  V and every time t we have:

[formula]

Note that relaxed isoperimetry is indeed a relaxation of the isoperimetric number: for Δ = 1 we have H(G)  =   min th(G(t)). Since hG(t) is a monotone function, we also get that the numerator is at least [formula] and scaling this by 1 / Δ can be interpreted as an average over the neighbor sizes. Indeed, if the average isoperimetric number of G(t) over every window of size Δ is at least h then we also have H(G) > O(h). If, e.g., the adversary chooses an empty graph every other round then the relaxed isoperimetry only gets reduced by a factor of 1 / 2. Furthermore, a large enough average isoperimetric number is required only for every subset individually and not simultaneously. This gives many always disconnected dynamic graphs a large relaxed isoperimetric number even though the isoperimetric number of G(t) is zero at any time. Lastly, iterating the neighborhood function hG(t) allows subsets to expand over Δ steps instead of just in their direct neighborhood. In summary, instead of requiring every set to expand at every time in its direct neighborhood the relaxed notion only calls for every individual set to have a high enough multi-step expansion on average.

The following lemma shows again that keeping just s = 1 active packets suffices to achieve the optimal performance of the RLNC protocol.

The synchronous broadcast FM-RLNC protocol with s = 1 takes with high probability at most [formula] steps to spread k messages in a dynamic network G.

A similar result can be proven for the asynchronous BROADCAST model [\cite=haeupler2010analyzing] in which at every round one node gets selected at random to broadcast its packet to its neighbors. To cover a very different model for our final example we choose a result on the performance of RLNC in the asynchronous single transfer model from [\cite=haeupler2010analyzing]. In this model, the adversary adaptively chooses a probability distribution over edges in each round from which the single transaction for the next round is then sampled. While for the RLNC protocol coding with binary coefficient (i.e., q = 2) works Lemma [\ref=lem:lowerbound] shows that this is not possible using finite memory. The next lemma demonstrates another way to circumvent this lower bound: using logarithmically many active packets suffices. In the same way as done for Lemma [\ref=lem:synchbroadcast], we replace the min-cut criterion by the weaker min-average-cut, i.e., a sufficient average cut over each finite time window of length Δ  =  O(1) for each subset individually.

In a dynamic network G with min-average-cut at least C, the asynchronous single transfer FM-RLNC protocol that uses binary coefficients (i.e., q = 2) and keeps only s  =  Ω( log n) active packets spreads n messages with probability at least 1 - 2- n in order optimal [formula] time.

Note that, e.g., choosing G(t) in every round to be the complete graph with uniform probabilities shows that the asynchronous random phone call model [\cite=algebraicgossip-deb-medard04-allerton] remains to spread rumors in optimal time if the FM-RLNC protocol is used.

Conclusion

This paper investigates the performance of RLNC with finite memory. We have presented two highly efficient variants of the packetized RLNC implementation in which each node only keeps one packet in active memory. We have furthermore given a very general analysis technique that allows to prove tight and order optimal stopping times for these FM-RLNC protocols in a wide variety of settings, including highly dynamic networks that are controlled by a fully adaptive adversary. In all cases considered here the performance of the FM-RLNC protocols is, up to small constant factors, on par with the full-blown RLNC protocol while offering a drastic reduction in memory and computational complexity. Subsequently we could show [\cite=optimalityNC] that, if one restricts the adversary to be oblivious, then both the RLNC protocol and its FM-RLNC variants stop with high probability in information theoretically optimal time: the protocols achieve with high probability the exact same stopping time as the best possible dissemination algorithm (using the same buffer sizes) even if this algorithm knows the (dynamic) topology in advance. This further supports the suggestions in this paper for a simple and efficient memory management scheme beyond the approaches in [\cite=sundararajan2007queueing] [\cite=sundararajan2008arq] [\cite=bhadra2007looking] [\cite=lun2006analysis]. We leave determining a good upper bound for the minimal needed buffer size as an open problem for future work but speculate that in practice choosing s slightly larger than the variance of the observed or expected traffic patterns might work.

Determining RLNC stopping times or, equivalently [\cite=optimalityNC], determining network capacities, remains an interesting and hard question for many network models; especially for the restricted memory setting addressed here. We believe that the generality and simplicity of the extended projection analysis technique developed in this paper will prove to be helpful in further studies on this topic.

Acknowledgments: We thank David Karger and Chen Avin for helpful comments.