Modeling self-organization of communication and topology in social networks

Introduction

Who communicates with whom and the social structure of a society are strongly entangled. The social network reflects the access to information that different parts of the system experience, and social mobility may be seen as a quest for better information access. A reliable global perception of the network, often achieved by informal communication with acquaintances [\citep=krackhardt] [\citep=bass] [\citep=brown] [\citep=knoke] [\citep=rogers] [\citep=huberman] [\citep=infoflow] [\citep=rosvall], makes the social mobility meaningful [\citep=friedkin] [\citep=dodds]. The small talk consists in its simplest form of identifying who to get the information from, and whom to transfer it to [\citep=milgram] [\citep=milgram1969] [\citep=kleinberg] [\citep=kleinberg-hierarchy] [\citep=kleinberg-algorithm] [\citep=wattsidentity]. To understand the feedback between different communication habits and the topology, we in this paper introduce an agent-based model that self-organize the social network. That is, we allow agents to create new links to get easier access to some parts of the system, based on interest and the information they obtained through communication with already established acquaintances [\citep=interestrewire] [\citep=friedkin-infoflow] [\citep=trusina2004].

After defining the model in the next section, we show that organized structures, that can make use of the small-world properties of the network [\citep=watts] [\citep=kochen] [\citep=perkins], emerge when the communication is sufficiently high. This is followed by an investigation of consequences of manipulating information. What are the gains or costs when the agents adopt individual strategies to get better access to the system on, respectively, local and global level? We investigate consequences of chatting, cheating and lying, and find, for example, that lying opens for a communication analogue to the prisoners dilemma game [\citep=axelrod]. Finally we explore a few variants of the model and, for example, show how separation of interests naturally leads to modular networks in the model.

Model

Let us now define the model in detail, formulated in the two basic events:

Communication: Select a random link and let the two agents that it connects communicate about a random third agent [\citep=bergmann]. The two agents also update their information about each other.

Rewiring: Select a random agent and let it use its information to form a link to shorten its distance to a randomly chosen other agent. Subsequently a random agent loses one of its links.

The communication event is typically repeated of the order of number of links in the system for each rewiring event. Figure [\ref=fig1] and [\ref=fig2] illustrate the two elements in the model. The basic variables in the network model are nodes represented by N agents and L links that correspond to the available communication channels in the system. We let the agents communicate and in that way build their own perception of where they are relative to other agents in the network. Each agent, in Fig. [\ref=fig1] exemplified by agent A, has a list of previously obtained information with entries for each agent i = A, B, C,[formula] For each entry i, the agent has a pointer to the agent that provided the most recent information about i. This pointer is updated if someone else comes with newer information about i [\citep=perkins]. Therefore we also keep the age of all obtained information in A's memory (see clocks in Fig. [\ref=fig1]). The age of an agent's information about itself is always 0. The age of any other information increases proportional to the number of ongoing communication events in the system. When two agents communicate about a third agent the agent with the older information disregards this and adopts the viewpoint of the agent with the newer information by copying the age and changing the pointer. In Fig. [\ref=fig1] agent A communicates with B about agent H, and adopts the viewpoint of B because B's information about H is newer. A sets its clock for H to the same time as B, and change its pointer for H to B. The age of the information serves as a qualifier that allows two communicating agents to estimate which of them that have the most reliable information.

Figure [\ref=fig2] describes the second main feature of the model, the social mobility. We implement the social constraints of who can connect to whom by only allowing new links from an agent to acquaintances of its acquaintances [\citep=bornholdt]. A randomly chosen agent, here A, is interested in shortening its distance to another randomly chosen agent in the system, here H. A therefore asks B, the agent that provided A with the newest information about H, about where the information came from. B answers E and A builds a link to E (if there is no link between A and B, A builds a link to B and stops after that). The creation of new links is balanced by random removal of links. This is illustrated in Fig. [\ref=fig2], where C, chosen randomly, looses its connection to D.

In the model, we thus have an interplay between the communication backbone network and the perception that the agents have of this network. The pointers of all agents, with both real and outdated links, form the perception network. In Fig. [\ref=fig3] we illustrate the concept of a communication backbone and the perception network at low and high communication in a small network with 25 nodes and 38 links. For relatively few communication events per rewiring (much less than the number of links in the system), the communication and perception network diverge and the rewiring that the agents perform has little to do with the real topology of the network. As a consequence, any rewiring of the network will be random and the network's overall topology disorganize into a structure with a narrow degree distribution [\citep=erdos] (see the two networks to the right in Fig. [\ref=fig3]). In contrast, a high communication implies that new links are introduced as a direct function of the present topology. They are typically directed towards highly connected nodes since they provide new information. With a tendency of building new links toward the majority of the system, a reliable perception opens for positive feedback and self-organization into a network with broad degree distribution (see the two networks to the right in Fig. [\ref=fig3]).

Results

To quantify the interplay between the self-organization of network topology and the overall communication level we in Fig. [\ref=fig4] and [\ref=fig5] show degree distributions for simulations of a system with N = 1000 agents, L = 2500 links, and different values of the communication level C. C  ·  L is the number of communication events per rewiring event in the network, and the degree k of a node is its number of links. We have also simulated networks with different number of links and found similar results with a tendency towards more pronounced non-random features with fewer links. In Figure [\ref=fig4] the number of communication events per rewiring and link is varied between C = 10- 4 and C = 100. At low communication level, C < 1, the perception network has many more links than the backbone network. As C approaches C  ~  1 the perception network prunes its links whereas the backbone network develops nodes with high degrees. At even higher values of C the two networks converge toward the same broad degree-distribution.

Beyond the degree distribution, we in Fig. [\ref=fig5] show the correlation profile (top), the average neighbor degree (middle) and the number of triangles (bottom) as a function of degree for low (left) and high (right) communication. In all cases we compare with a randomized network where the degree sequence is identical to the model generated, but all other features are reshuffled [\citep=maslov2002]. We chose C = 10- 2 as the low and C = 1 as the high communication level. The overrepresentation of links between nodes of high and low degree gives extended community structures. Triangles are overrepresented around low-degree nodes and underrepresented around high-degree nodes [\citep=watts].

All the presented results until now are based on agents that all are the same. At any time their social position will however be different, because their sequence of communication and rewirings is strongly influenced by the history of the system. The presented model describes a social game where the aim is to be central, and a winner is an agent with many connections that provide short and reliable communication to other agents. The fact that we observe agents with a wide range of degrees reflects the diversity of the possible outcomes of the game, and raises the questions about whether there are some particular strategies with which agents can improve their standing in the network? Can acting like a winner make you more likely to become a winner? Are there some particular situations where agents systematically can attract additional connections and become a hub?

A highly connected agent became highly connected because it attracted new links by providing new information about other agents. To provide new information is essential to win the game. We therefore investigate a number of individual strategies where agents attempt to convince other agents about their attractiveness as an acquaintance.

Chatting represents an increased communication rate. We let the chatters communicate twice as much as other agents by increasing the probability that their links are chosen for a communication event by a factor 2. Note that this also affects their acquaintances because they share links with the chatters.

Cheating represents a decreased clock-speed. We let the cheaters use clocks that run at half the speed of the other agents' clocks, and their information will thereby have a slower aging. In practice they cheat by pretending that they have newer information than they really have. Cheating might be either deterministic (every time unit is half length) or stochastic (a time unit is counted with probability 1 / 2).

Lying represents a pure lie about the age of the information in a communication event. Instead of updating the clock, the liars replace the time by a random number. Here we choose the random number between 1 and 100 that represents the typical age of information about an agent within the second nearest neighbor radius in a system with 1000 agents.

In all three strategies the information is manipulated to gain a local advantage. However, there may also be a cost, both on local and on global scale. This is what we examine in Fig. [\ref=fig6] and [\ref=fig7]. Figure [\ref=fig6] shows the topological consequences on the communication backbone and Fig. [\ref=fig7] the effect on the perception network, as we vary the number of strategic agents between 1 and the system size at communication level C = 1. The right panel in Fig. [\ref=fig6] shows how the max degree of respectively the strategic agents (black circles) and non-strategic agents (orange squares) changes with [formula]. When less than about 10 agents adopt any of the three strategies the they gain in terms of degree. However, as the number of liars increase, the overall network topology degenerates and it becomes impossible to sustain hubs. Also the liars become losers. A more global examination of the effect of the various strategies are shown in left panel of Fig. [\ref=fig6]. The efficiency E = 〈1 / dij〉 is the average value of the reciprocal distance [\citep=latora] of, respectively, the strategic agents, and the non-strategic agents. This measure of typical distances in the network allow us to include also temporarely disconnected nodes. In terms of efficiencies all strategies are successfully, and in addition they also seem to benefit the other agents by providing short paths.

That the strategic agents become central in the communication backbone-network does not directly imply that they can use their centrality. The use of various strategies may influence the reliability of information that the agents have about the system and thereby make long-distance communication more difficult. In Fig. [\ref=fig7] we examine the ability of agents to communicate across the system. [formula] in the left panel is the average number of agents that participate in communicating a message from an agent to another agent. For chatters, we again see that everybody gains. For cheaters, on the other hand, everybody gains if the cheating is deterministic, but already a few agents with stochastic cheating (faded) makes communication across the system less efficient. The from Fig. [\ref=fig6] seemingly successful strategy of lying completely destroy the communication abilities (Fig. [\ref=fig7](e)). One single liar makes some benefit of its strategy, but two liars are enough to not only destroy for the nonliars, but also for the liars themselves.

To emphasize this result, we in the right panel of Fig. [\ref=fig7] show the reliability, [formula], of the perception network. To calculate [formula], we send messages between any pairs of node and let the intermediate agents route the messages with their pointers. A message fails when it reaches an agent for the second time and the path forms a loop. [formula] is the fraction of messages that reach the target. The chatters are able to keep perfect reliability, but the cheaters and especially the liars destroy it. When there are 1000 deterministic cheaters the reliability is again 100% (see Fig. [\ref=fig7](d)). This is because it only corresponds to a rescaling of time when all agents are deterministic cheaters. The liars, examined in Fig. [\ref=fig7](f), systematically destroy the signaling capacity of the network.

The presented model is the simplest in a family of models based on an interplay between communication and dynamical changes of topology. We have investigated a range of variations, including versions where each agent has a biased interest in other agents. For example, we let an agent's target of interest be chosen inversely proportional to the age of the information about the target [\citep=java]. Thereby interests are focused around the neighborhood and we observe an increase in the number of triangles in the system. In another variant, we divided the agents into several interest groups. By increasing the probability to communicate and move inside the interest group, the network develops a modular topology.

Discussion

In this work we have introduced a model framework that allow us to investigate the interplay between social structures and communication habits. We have shown that low communication leads to random networks with narrow degree distributions. Increased communication naturally gives nonrandom structures characterized in particular by social networks with broad degree distributions. In addition to developing broad degree distributions, the networks also tend to organize highly connected agents to connect preferably to low connected agents.

With the model, we have investigated how manipulating information influence the social structure, quantified by the topology of the emerging network. Firstly we increased the communication frequency of individual agents. The result was striking, the more an agent chats with its surroundings, the better it performs. Increased chatting requires increased effort, but our model shows that there is both a local and a global gain to this effort.

Secondly we investigated the effect of cheating with the age of the information a particular agent distributes. If an agent only underestimated the time since it received the information, the agent improved its position but at a cost to the remaining system. As cheating does not cost more communication effort of the agent, it is the cheap way to optimize the social position selfishly. However, already a single cheater decreases the overall reliability to send signals across the network, reflecting a moderate global cost to this strategy.

Thirdly we investigated the more violent strategy of lying. The lying agents pretend that they have recent information about everybody else. The strategic agents in this way succeed to attract links and thereby become central in the communication backbone network. However, only a single liar in a system with non liars benefit from the strategy. Lying is so destructive that one liar is enough to break down the reliability of the network and none is in reality a winner.

Summary

In a broad perspective the proposed model suggests an information theoretical perspective on social and possibly also economic systems. By introducing an information game based on social links and communication rules we present an approach to the dynamics of human organization. Agents in a network use information, obtained through communication in the network, to form new links for better access to information. The introduced feedback enables us to study the topological consequences of different communication habits. By playing this communication game, we learn that communication, although not equally distributed, is a benefit for everyone. However, communication is expensive. Other cheaper strategies are tempting, but a strategy based on lies easily counteract the intention to have better access to information. The social possibilities are not solely defined by the position in the network, but also by the quality of the surrounding information.