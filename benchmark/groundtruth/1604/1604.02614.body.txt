On the performance of exponential integrators for problems in magnetohydrodynamics

Introduction

The focus of this article lies at the intersection of computational plasma physics and numerical analysis. The system of resistive magnetohydrodynamics (MHD) equations is used extensively in both laboratory and astrophysical plasma physics [\cite=goedbloed2004]. MHD simulations are employed to study large scale plasma dynamics in applications ranging from design of the next generation of fusion devices to modeling astrophysical jets (e.g. [\cite=kuwabara2005] [\cite=ebrahimi2015] [\cite=zanni2007]). Since experiments in this field usually impose a high cost and the ability to conduct observations can be very limited, computational modeling in general, and numerical MHD in particular, have become very important components of research in plasma physics. While MHD theory is widely used to study plasma dynamics, the complexity of the MHD equations makes their numerical solution a challenging task. In particular, the MHD system describes a wide range of temporal scales. In applications such as large scale modeling of tokamaks or modeling of solar eruptions, the physical processes of interest evolve on the time scale of the shear Alfvén waves, which is much slower than the fastest mode in the system - the fast magnetosonic wave - and much faster than the slow magnetosonic wave and the resistive processes. Such temporal stiffness coupled with the complexity of the equations poses a double-edged challenge to developing a time integrator for MHD. From one perspective, the stiffness implies that explicit time integrators will suffer from prohibitively severe restrictions on the time step size due to stability considerations. On the other hand the inherent three-dimensional nature of the processes MHD describes and the complexity of spatial operators describing the dynamics makes evaluation of forcing terms computationally expensive. The latter difficulty served as one of the major reasons most large scale MHD codes came to rely extensively on explicit time integrators even for problems where resistivity plays a major role. However, the temporal stiffness of the equations forced researchers working on these software packages to turn to at least some form of implicitness to overcome the small time steps sizes of explicit integrators [\cite=jardin2012]. Production codes used in fusion research and astrophysics [\cite=NIMROD] [\cite=M3D] [\cite=FLASH] started embedding some form of implicitness into their time integration schemes. The NIMROD code, for instance, employs an implicitly integrated term in the momentum equation derived by linearizing equations around a static magnetic field and using it to stabilize stiff wave components [\cite=sovinec2010] [\cite=NIMROD]. In addition to this stabilizing term the overall time integration strategy also uses operator splitting and a staggered temporal grid. The choice of the implicit terms in such semi-implicit schemes is also influenced by the availability of efficient algebraic solvers used to approximate solutions to the associated linear systems. The complexity of the resulting overall time integration method makes it very difficult to use rigorous analysis to study stability and convergence. Such an approach also precludes or makes it challenging to derive error estimators necessary for employing adaptive time stepping strategies or using the time integration as part of the uncertainty quantification methods. Other partially implicit approaches such as alternating direction implicit (ADI) methods [\cite=lindemuth73] [\cite=schnack_killeen80] or implicit-explicit techniques [\cite=keppens99] are also limited as they try to maintain a balance between stabilizing the time integration while maintaining the accuracy of the solution [\cite=chacon08]

The difficulties associated with partially implicit methods and the ever pressing need for more efficient and accurate algorithms for high-performance computing platforms gave rise to the efforts to develop fully implicit time integrators for resistive MHD [\cite=reynolds2006] [\cite=reynolds2012] [\cite=chacon08] [\cite=lutjens10]. A typical approach to constructing a fully implicit integrator involves using an implicit scheme such as, for instance, BDF and coupling it with a Newton-Krylov iteration to solve the implicit equations within each time step. In [\cite=reynolds2006] [\cite=reynolds2012], for example, the resistive MHD equations are solved using a variable order variable time step BDF method from the CVODE portion [\cite=cohen1996] of the SUNDIALS package [\cite=SUNDIALS]. While implicit methods possess better stability properties compared to explicit techniques, they are also affected by the stiffness of the equations. In an implicit integrator temporal stiffness manifests itself in the stiff linear systems that have to be solved as part of each Newton iteration. A key to obtaining an efficient fully implicit Newton-Krylov solver is in developing effective scalable preconditioners for these stiff linear systems. For a complex anisotropic system such as MHD construction of a sufficiently efficient preconditioner is simultaneously a central and a challenging task that requires a significant investment of time and effort. If the parameter regime is changed or an extra term is added to the system, it is possible that a new preconditioner has to be developed. Often the structure of the equations is exploited to build a physics based preconditioner [\cite=chacon08] which makes the overall integrator highly dependent on the equations, thus precluding one from using off-the-shelf time integration software packages.

In recent years exponential integrators have emerged as a promising alternative to explicit and implicit methods for solving evolution equations. A significant body of research has been accumulated in which these methods are investigated both from a theoretical (see e.g. [\citep=hochbruck2010] for a review article) as well as from a numerical point of view (see e.g. [\citep=tokman2010] and [\citep=loffeld2012]). This research includes the construction of exponential integrators that have been tailored to a given differential equation (see e.g. [\citep=hochbruck1999]) as well as such integrators that can be applied to a class of problems (see e.g. [\citep=hochbruck2005] [\citep=tokman2006]). There is strong evidence to suggest that exponential integrators can offer computational advantages compared to standard integrators particularly for large scale complex problems where no efficient preconditioner is available. Exponential integration can also be used as part of an Implicit-Exponential (IMEXP) scheme [\cite=tokman14] for problems where an efficient preconditioner has been constructed for some terms in the equations.

Exponential integrators were first shown to be a promising approach in the context of the MHD equations in [\cite=tokman2001] [\cite=tokman2002]. Since then a number of more efficient and sophisticated exponential time integrators have been developed. Exponential propagation iterative methods of Runge-Kutta type (EpiRK) were first introduced in [\cite=tokman2006] for general nonlinear systems of ordinary differential equations. The EpiRK framework [\cite=tokman2006] [\cite=tokman2010] [\cite=tokman14] for constructing exponential time integrators has been designed to reduce computational complexity in each time step and provide a flexible ansatz that allows construction of particularly efficient exponential schemes [\cite=tokman2010] [\cite=tokman2011] [\cite=rainwater14] [\cite=tokman14]. The most efficient EpiRK methods have been implemented as part of the Exponential Integrator Collection (EPIC) package, a C++/MPI software developed for serial and parallel computational platforms (available for download by request to mtokman@ucmerced.edu). Performance of EPIC integrators has been tested on a suit of numerical examples and it was shown that the EpiRK schemes can achieve superior or equal performance compared to the BDF integrator found in the CVODE library [\cite=loffeld2012] [\cite=loffeld14].

However, up to now most numerical tests of exponential methods found in the literature considered problems of small to medium complexity (see, for example, [\citep=loffeld2012], [\citep=klein2011], or [\citep=einkemmer2013]) where in many instances efficient preconditioners can be constructed. The goal of this paper is to apply the EpiRK integrators found in the EPIC library to the problem of solving the resistive magnetohydrodynamics (MHD) equations. General preconditioners for such systems have, for example, been investigated in [\citep=reynolds2012] and it was found that constructing an efficient preconditioner for such system is challenging and the the performance gain from standard preconditioning techniques for several dimensional examples is rather modest under most circumstances. Clearly a problem specific preconditioner or a tailor-made time integrator for a specific system of equations will be the most efficient approach in the majority of cases, but developing such a scheme requires extensive effort and time. The goal of this paper is to investigate what computational savings can be achieved with a general exponential integrator compared to an unpreconditioned implicit scheme. Thus we will perform a comparison of EPIC integrators with the BDF methods from the CVODE library without a preconditioner. We aim to demonstrate that exponential integration is a viable technique to use in integrating MHD equations.

The paper is organized as follows. In section [\ref=sec:Exponential-integrators] we provide an introduction to exponential integrators in general as well as to the specific EpiRK methods we use in the numerical examples and their implementation in EPIC. In section [\ref=sec:magnetohydrodynami] we describe the MHD equations which are solved numerically in section [\ref=sec:The-reconnection-problem] for a reconnection problem, and in section [\ref=sec:The-Kelvin-Helmholtz-instability] for the Kelvin-Helmholtz instability. Implementation details are discussed in section [\ref=sec:Implementation]. Finally, our conclusions are presented in section [\ref=sec:Conclusion].

Exponential integrators

Let us consider the following initial value problem

[formula]

which is assumed to be large and stiff. Before proceeding to describe the class of numerical methods we are interested in, let us use a Taylor expansion to write the right hand side of ([\ref=eq:ivp]) in the following form

[formula]

where J(y(t)) = DyF(y(t)) is the Jacobian and the remainder function is given by

[formula]

Now using the Gröbner-Alekseev formula (or an integrating factor e- hJ), we obtain

[formula]

This integral representation of the solution can be used as a base for constructing an exponential integrator as follows. First, the nonlinear integral in ([\ref=eq:intivp]) has to be approximated in a suitable manner. If this is done using a polynomial approximation of the function R(y(t + sh)) we express the integral as a linear combination of the entire functions defined by

[formula]

The numerical solution is then approximated as a linear combination of the products of matrix functions and vectors φk(chJ)v where c is a constant. These approximations constitute the main computational cost of an exponential method, therefore choosing an appropriate algorithm is essential to obtaining an efficient integrator. A number of methods have been proposed in the literature to approximate either a general or a specific (e.g. rational or exponential) function of a matrix or its product with a given vector (e.g. [\cite=vandervorst] [\cite=niesen2012] [\cite=almohy2011] [\cite=kassamtrefethen] [\cite=leja] or see the review in [\cite=hochbruck2010]). However, many of these techniques are applicable only to small matrices J [\cite=molervanloan] [\cite=sidje]. In this paper we are concerned with large scale problems such as MHD, where the dimensionality of the system [\eqref=eq:ivp] is high (e.g. number of unknowns in MHD equations multiplied by the number of grid points in two- or three-dimensions), and thus standard techniques for approximating a product of a matrix function φk with a vector are either computationally infeasible or prohibitively expensive. One possibility is to use a polynomial approximation of φk. To that end we have to chose m interpolation nodes on some compact set [formula]. Chebyshev nodes are an obvious choice, however, they suffer from the disadvantage that to compute the interpolation for m + 1 points we have to reevaluate all the matrix-vector products already computed. To remedy this, Leja points have been proposed which share many of the favorable properties of the Chebyshev nodes but can be generated in sequence [\cite=leja] [\cite=martinez2009] [\cite=caliariostermann] [\cite=leja_relpm]. Another advantage of interpolation at Leja points is its modest memory requirements. This makes it an attractive alternative for computer systems where memory is limited (such as graphic processing units, see [\citep=einkemmer2013]). The main disadvantage of the method, however, is that (at least) some approximation of the spectrum of J has to be available. Since approximating the spectrum of a Jacobian matrix in MHD can be a very computationally expensive task, in this paper we focus exclusively on a more general approach based on the Krylov projection algorithm [\cite=arnoldi] [\cite=vandervorst].

Krylov methods have been extensively used to approximate the inverse of a matrix [\cite=saad] and in 1987 were employed by Van der Vorst to approximate a general function of a matrix and a vector product [\cite=vandervorst]. The algorithm works by iteratively computing a projection of φk(chJ)v onto a Krylov subspace

[formula]

using the Arnoldi algorithm [\cite=arnoldi]. The dimension of the Krylov subspace m is determined dynamically by estimating the residuals in the course of the iteration [\cite=saadresid] [\cite=hochbruckkrylov]. For each m a matrix Vm is formed that consists of the orthonormal vectors vi (i  =  1,...,m) that form the basis of Km(chJ,v). A side product of the Arnoldi iteration is the m  ×  m matrix Hm  =  chVTmJVm which represents the projection of chJ onto the Krylov subspace. A general product of the matrix function f with a vector is then approximated as

[formula]

Note that Hm is a matrix of dimension m  ×  m and therefore the application of φk(Hm) to a vector can be easily computed by using any of the standard methods (such as Pade approximation or methods based on polynomial interpolation [\cite=molervanloan] [\cite=hochbruck2010]).

Since evaluations of φk(chJ)v constitute the most computationally expensive part of the exponential integrator, special care has to be taken to ensure that each time step requires as few of these evaluations as possible and the most efficient algorithm is chosen for these approximations. The EpiRK framework [\cite=tokman2006] [\cite=tokman2011] is designed to construct integrators with a reduced number of φk(chJ)v evaluations and with φk functions chosen to speed up the Krylov iteration. A particularly efficient class of EpiRK methods [\cite=tokmanadapt] also takes advantage of an adaptive version of the Krylov iteration introduced in [\cite=niesen2012]. The adaptive Krylov based EpiRK schemes link the construction of a time integrator with the choice of the method to approximate φk(chJ)v to build a more efficient overall time stepping scheme in the following way.

The computational cost of the Krylov algorithm to approximate terms of type φk(chJ)v scales as O(m2) with the size of the Krylov basis m. Clearly, m depends on the eigenvalues of J, vector v as well as the values of c and h. As c or h is increased, so is the size of the basis. The EpiRK framework allows one to reduce the coefficients c and choose the better suited functions φk in the derivation of a time integrator. The adaptive Krylov technique allows replacing each computation of φk(chJ)v with several evaluations of φk(τichJ)v where 0  <  τi  <  1 for i  =  0,1,2,...P. Since the complexity of each of these evaluations now scales as O(m2i), in most cases increased efficiency is observed as O(m2) can be less than O(m21) + O(m22) + ... + O(m2P).

A general EpiRK method can be written as

[formula]

where the divided differences Δ(h - 1)R(yn) are computed by using the nodes [formula]. Different choices of functions ψij and matrices Jij result in different classes of EpiRK methods such as unpartitioned, partitioned or hybrid exponential or implicit-exponential (IMEXP) integrators [\cite=tokman14]. In this paper we employ the schemes with the choice of Jij = Jn and ψij set as linear combinations of φk functions

[formula]

As in the Runge-Kutta case, to construct an efficient integrator the coefficients aij,gij,bj and pijk have to be chosen subject to the appropriate order conditions. In this paper, we use the variable time step fifth order method EpiRK5P1

[formula]

that has been derived in [\citep=tokman2010] (see Table [\ref=tbl:epirk5p1] for the coefficients; this method is also employed in the performance comparison given in [\citep=loffeld2012]) and the constant time step fourth order EpiRK4 method proposed in [\cite=rainwater2016] given by

[formula]

Both of these EpiRK schemes utilize the adaptive Krylov technique for the evaluations of φk(chJ)v in order to improve performance. It is important to note that while both of these are three-stage methods, EpiRK4 requires only two Krylov projections to be executed per time step since the scale invariance of the Arnoldi iteration allows simultaneous calculation of the Krylov bases for Y1 and Y2 and one more Krylov projection to evaluate yn + 1 (e.g. see [\cite=rainwater2016] for details). EPIRK5P1 requires three Krylov projections to be performed each time step [\cite=tokmanadapt]. In addition EPIRK4 is a so-called stiffly accurate method while EPIRK5P1 is derived using classical order conditions. The advantages of the EPIRK5P1 method, however, include the higher order and the ability to design embedded methods for the automatic time step control that do not require an additional Krylov projection. The adaptive time step control version of the methods of type EPIRK4 is still under development.

The resistive magnetohydrodynamics equations

The most fundamental theoretical description of a classical plasma comes from the kinetic equation. This so called Vlasov equation (the collisionless case) or Boltzmann equation (when collisions are of physical significance) describes the time evolution of a particle-density in the 3 + 3 dimensional phase space (the first three dimensions correspond to the space dependence while the remaining correspond to the velocity dependence of the particle-density). While a number of simulations of different plasma phenomena have been conducted with this approach, due to the high dimensionality of the phase space, a lower-dimensional approximation is usually used to render such simulations feasible. A similar discussion holds true for the gyrokinetic approximation that can be employed in plasmas where a strong external magnetic field along a given axis is present. In this case the phase space of the Vlasov equation is reduced to 3 + 2 dimensions by averaging over the gyro motion. This procedure yields a good approximation under the assumption of low frequency as compared to the cyclotron frequency. For a more detailed discussion of gyrokinetic models, see e.g. [\citep=frieman1982] or [\citep=fahey2008-2QOYZWMPACZAJ2MABGMOZ6CCPY].

However, in many applications (such as magnetic confinement fusion, spheromak experiments, and astrophysical plasmas) the timescales of interest are sufficiently long and/or the full three dimensional model is necessary to describe the physical phenomena. In that case the kinetic approach is usually not feasible (even on modern day supercomputers) and thus further simplifications have to be introduced. For the magnetohydrodynamics (MHD) equations, which we will describe in the remainder of this section, the assumption is made that, to a good approximation, the distribution in the velocity direction is Maxwellian; in other words, it is assumed that each sufficiently small volume in the plasma is in thermodynamic equilibrium. For a general overview of kinetic and MHD models (including a derivation of the MHD equations from the Vlasov equation) see e.g. [\citep=nicholson1983]. Numerical computations in the context of the MHD model discussed in this paper are performed, for example, in [\citep=reynolds2006], [\citep=reynolds2010], and [\citep=reynolds2012].

If the assumption is made that the plasma considered is in thermodynamic equilibrium, the equations of motion in a three dimensional phase space (a so called fluid model) can be derived. These are given by (in dimensionless units)

[formula]

which we refer to as the continuity and momentum equation respectively. The equations are written in terms of the density ρ, the fluid velocity [formula], the magnetic field [formula], the electric current density [formula] , and the pressure p. The dynamics is determined by the Lorentz force (the [formula] term) and the pressure gradient force (the [formula] term). These fluid equations have to be coupled to an appropriate model of the electric field. Note, however, that if the (ideal) Ohm's law is assumed to hold, i.e.

[formula]

then the electric field [formula] can be eliminated from Maxwell's equation. This leaves us with the following system

[formula]

The first of these equations yields the time evolution of [formula], the second can be used to eliminate [formula] from equation ([\ref=eq:momentum-equation]), and the third is the familiar solenoidal constraint imposed on the magnetic field.

A commonly employed approach to close these equations (see e.g. [\citep=reynolds2010]) is to supplement them with the following equation of state

[formula]

where the time evolution of the energy density e is given by

[formula]

Collectively, the equations ([\ref=eq:continuity])-([\ref=eq:energy]) in the variables [formula] yield a first-order system of 8 differential equations in 8 variables and are called the ideal magnetohydrodynamics equations (or the ideal MHD equations).

For the purpose of performing the spatial discretization, these equations are often cast into the so-called divergence form. Then, the equations of motion read as (see e.g. [\citep=reynolds2010])

[formula]

with state vector

[formula]

and

[formula]

where we have denoted the tensor product by using the [formula] symbol.

In this paper, as in [\citep=reynolds2006] and [\citep=reynolds2010], we will consider a slightly more general class of equations which, in addition to the dynamics discussed so far, includes dissipative effects (due to particle collisions in the plasma). To that end the hyperbolic flux vector F(U) is extended in [\citep=reynolds2006] by a diffusive part given by

[formula]

with

[formula]

where we have assumed a spatially homogeneous viscosity μ, resistivity η, and thermal conductivity κ. The non-dimensional parameters governing the solution of this system are the Reynolds number Re = ρ0vAl0  /  μ, the Lundquist number S = μ0vAl0  /  η and the Prandtl number Pr = cpμ  /  κ for a characteristic density ρ0, a characteristic length scale l0, and the Alfven velocity vA (as usual the permeability of free space is denoted by μ0, κ = 5 / 3, and cp is the specific heat of the fluid).

Note that in all the simulations we use dimensionless units. Thus, we can rewrite ([\ref=eq:Fd]) more conveniently in terms of the (dimensionless) viscosity μ = Re- 1, the (dimensionless) resistivity η = S- 1, and the (dimensionless) thermal conductivity κ = Pr- 1. Then, the form of the resistive MHD equations used for the spatial discretization is

[formula]

with F(U) given by equation ([\ref=eq:F]) and where Fd(U) is given by

[formula]

For the numerical simulations conducted in this paper, we employ the MHD code developed in [\cite=einkemmercppmhd]. This C++ code is based on the Fortran code developed in [\citep=reynolds2006] which has been used to conduct plasma physics simulations (see e.g. [\citep=reynolds2006], [\citep=reynolds2010], and [\citep=reynolds2012]) as well as to construct more efficient preconditioners in the context of implicit time integrators (see [\citep=reynolds2010]).

Our implementation assumes a finite difference or finite volume method where a single value is stored in each cell. Thus, in each cell we store the value of the density ρ, the fluid velocity [formula], the magnetic field [formula], the energy e (but not the pressure p). For the numerical simulations conducted in this paper, we have implemented the 2.5-dimensional case (that is, the state variables only depend on the x- and y-direction but both the velocity [formula] and the magnetic field [formula] are three-dimensional vectors) using a classic centered stencil for the divergence; that is, for each vector G, corresponding to the flux of a given (scalar) state variable, we compute the following approximation of the divergence

[formula]

where i and j are the cell indices in the x- and y-directions, respectively and h is the cell size. To evaluate the spatial derivatives present in the diffusion vector Fd, we also employ the classic centered stencil. Thus, the code has order two accuracy in space.

It is well known that for MHD problems preserving the divergence free property of the magnetic field is important. The space discretization used in our implementation ensures that if the solenoidal property [formula] is satisfied for the initial value, then this is true for all later times. In [\citep=reynolds2010] it is shown that this property also holds true if we couple the space discretization with an implicit method that is based on a matrix-free inexact Newton– Krylov algorithm. In addition, the numerical simulations conducted suggest that the divergence free condition is preserved if an exponential integrator is used for the time discretization.

The reconnection problem

The examples in this and the next section are drawn from [\citep=reynolds2006] and [\citep=reynolds2010], respectively. We start with a reconnection problem for which the initial value of the magnetic field is given by

[formula]

where as in [\citep=reynolds2006] we have chosen kx  =  π / xr, ky  =  π / (2yr), ψ0 = 0.1, and the computational domain is given by ×  [ -  yr,yr] for xr = 12.8 and yr = 6.3. This implies that the magnetic field reverses direction from pointing along [formula] to pointing along [formula] abruptly at y = 0. Furthermore, we impose a density that is given by

[formula]

and a pressure that is proportional to the density; to be more precise p = 0.5ρ (from which the energy is determined). A vanishing velocity in both space directions is prescribed.

The time evolution for the current is shown in Figure [\ref=fig:recon-snapshots]. In all the simulations conducted the relative tolerance, the absolute tolerance, and the tolerance for the Krylov iteration are equal. We have investigated the effect of varying the tolerance for the Krylov iteration and found no significant difference in accuracy or run time as long as we choose a tolerance for the Krylov iteration that is at least as small as the tolerance for the time integration.

First, we consider the configuration that is investigated in [\citep=reynolds2006]; that is, we employ 256 grid points in the x-direction and 128 grid points in the y-direction. The results obtained are shown in Figure [\ref=fig:reconnection-256x128]. We observe that the performance of the EPIRK5P1 method is superior to CVODE if the desired accuracy is equal or less than 10- 4. In the low precision regime that is often of interest in applications, EPIRK5P1 outperforms CVODE by almost a factor of 2. However, for more stringent tolerances the CVODE implementation is significantly more efficient. This is due to the fact that the run time for the CVODE method is almost independent of the accuracy achieved. What is perhaps even more interesting is that for a specified tolerance of 10- 4 or above the CVODE method does not converge (in the situation described a final step size on the order of 10- 16 is reported by the application). Let us also note that the constant time step method EPIRK4 is not competitive for this problem.

Next, we investigate the effect of increasing the number of grid points. The results obtained with 512 grid points in the x-direction and 256 grid points in the y-direction are shown Figure [\ref=fig:reconnection-512x256]. In this case almost identical conclusions can be drawn. Once again the performance of EPIRK5P1 is superior to CVODE library if the desired accuracy is equal or less than 10- 4. Furthermore, the constant step size method EPIRK4 is not competitive except for very stringent tolerance requirements.

Up to this point we have only considered relatively large values for the viscosity, resistivity, and the thermal conductivity. Thus, we proceed by decreasing these dimensionless quantities by a factor of five. The corresponding results are shown in Figure [\ref=fig:reconnection-eta-1]. In this case the EPIRK5P1 implementation outperforms the CVODE implementation for all the tolerances studied here (although the difference in performance between the two methods in the low precision regime is smaller than was the case for the previous two examples). For accuracies between 10- 6 and 10- 8 the constant time step method EPIRK4 manages to outperform both the EPIRK5P1 as well as CVODE implementation.

We observe that for larger Reynolds and Lundquist numbers the EpiRK method shows better or identical performance for the range of tolerances studied here. In addition, the EpiRK method shows a clear advantage over the CVODE implementation for tolerances larger than 10- 5.

In summary, it can be said that for the reconnection problem the EPIRK5P1 implementation shows superior performance in the large and medium tolerance range that is of interest for the majority of practical applications. However, for some of the examples considered here the CVODE implementation has a significant advantage for more stringent tolerance requirements.

To conclude this section let us investigate the strong scaling (i.e. the problem size is kept fixed while the number of cores is increased) for both our time integration routines and the CVODE implementation. This allows us to ascertain how well the current implementation is parallelized. In the ideal case we would observe a linear decrease in the run time as a function of the number of cores.

The strong scaling results on the VSC-2 are shown in Figure [\ref=fig:scaling] and are almost identical for both implementations. We conclude that the algorithms scale well up to approximately 256 cores. No further gain in performance can be observed for 1024 or more cores. This is to be expected as in the case of strong scaling the amount of work available to a single core eventually decreases sufficiently such that communication between he different MPI processes limits the performance of the application. At this point no further increase in performance can be expected.

The Kelvin-Helmholtz instability

As a second example we consider the Kelvin-Helmholtz (KH) instability. The KH instability is triggered by superimposing the following perturbation

[formula]

in the x-direction on the velocity field

[formula]

The density is initialized to unity and a uniform pressure is chosen. The magnetic field is initialized to be uniform in both the x- and z-direction with strength Bx and Bz, respectively, and is assumed to vanish in the y-direction. All the parameters used to determine the numerical value of the initial value are listed in Table [\ref=tab:kh-parameters].

The time evolution of the numerical solution is shown in Figure [\ref=fig:kh-snapshots]. In all the simulations conducted the relative tolerance, the absolute tolerance, and the tolerance for the Krylov iteration are equal. We have investigated the effect of varying the tolerance for the Krylov iteration and found no significant difference in accuracy or run time as long as we choose a tolerance for the Krylov iteration that is at least as small as the tolerance for the time integration.

First, we perform a numerical simulation of the Kelvin-Helmholtz instability for 128 grid points in both space directions. The results obtained are shown in Figure [\ref=fig:kh-128]. Both exponential integrators considered here (EPIRK5P1 and EPIRK4) outperform the CVODE implementation by a significant margin (approximately a factor of two). Furthermore, CVODE is very sensitive to even small perturbations in the chosen tolerance, while the exponential integrators are much more robust in this regard. Thus, a user who would naively (i.e. without measuring the run time for a range of tolerances) choose a specific tolerance would increase the run time of the application by significantly more than the factor of two stated earlier. What is also interesting to see is that the constant step size method EPIRK4 is equal in performance or outperforms EPIRK5P1 for all tolerances studied here (although the difference between these two methods is at most 30%).

Now, let us increase the number of grid points to 256 (in both space directions). The corresponding results are shown in Figure [\ref=fig:KH-512]. As before, we observe that both exponential integrators significantly outperform the CVODE implementation. In addition, the constant step size method EPIRK4 outperforms the EPIRK5P1 implementation by up to 30%. This is also consistent with the results on the coarse grid considered before. Let us emphasize here again that the major advantage of EPIRK4 is that it uses fewer Krylov projections (two vs. three for EPIRK5P1) per time step. However, at present this advantage over EPIRK5P1 is limited to constant time step implementations. A third projection is needed to construct automatic time stepping control schemes for EPIRK4. The variable time stepping version of the integrators is more efficient for EPIRK5P1 since it is a higher order method. For the Kelvin-Helmholtz instability, considered in this section, these differences work in favor of the EPIRK4 method while for the reconnection problem, considered in the previous section, the EPIRK5P1 scheme is superior (in the case of low and medium tolerances).

In summary, both exponential integrators considered in this paper show significantly improved performance compared to CVODE for the Kelvin-Helmholtz instability. Let us also mention that for both the exponential integrators as well as CVODE it is not entirely straight forward to choose a good tolerance. This is due to the fact that if the tolerance is chosen too high, the run time can actually increase. We emphasize, however, that this behavior is significantly more serious for the CVODE implementation.

Implementation

We have chosen to base our implementation on the 2.5 dimensional MHD code developed by Daniel R. Reynolds et al.. A large number of numerical simulations have been conducted (see e.g. [\citep=reynolds2006] and [\citep=reynolds2010]) and the performance of preconditioners for Newton-Krylov based implicit methods has been investigated (see e.g. [\citep=reynolds2010]). Furthermore, the extension of the code to three dimensional problems as well as to non-square geometries (such as a Tokamak geometry) have been investigated in [\citep=reynolds2012].

Our code is implemented in C++ and is designed to easily accommodate different time integrators, space discretization schemes, as well as different MHD models. The design considerations and a detailed description of the computer code can be found in [\citep=einkemmercppmhd].

The second component of our code is the EPIC library (see [\citep=loffeld2012]) which implements the fifth order EpiRK5P1 with an adaptive time step control (EpiRK5P1VerticalVar function in EPIC library), the fourth order EpiRK4 method (EpiRK4MixedConst function in EPIC library) with constant time steps and the adaptive Krylov algorithm to evaluate the φk functions as described in [\citep=niesen2012]. This library is written in the C++ programming language with MPI, and uses routines from the BLAS and LAPACK libraries. In the experiments, the BLAS and LAPACK implementations were supplied by the Intel Math Kernel Library (Intel MKL).

One detail warrants further discussion: in the original Fortran program the CVODE interface is used to approximate the Jacobian by a simple forward difference stencil. In our implementation, however, we provide a custom function to compute an approximation to the Jacobian. This is necessary for the EPIC library, which before was only used in the context of problems where an exact Jacobian is available (as in [\citep=loffeld2012]). Computing an exact Jacobian for the significantly more complex MHD problem considered in this paper is infeasible. Therefore, we have to approximate J(a)v, i.e. the application of the Jacobian J at position a to a vector v, where both a and v depend on the specific numerical algorithm as well as the initial values. We note here, that there is a qualitative difference in the norm of the vector v that depends on the numerical time integration scheme used. In the EpiRK the norm of v is close to unity whereas in the BDF method the value is often significantly below [formula] (where we use [formula] to denote machine precision). Therefore, care is taken to scale vectors to the norm [formula] only if the initial norm is above [formula] in magnitude. Then the same implementation can be used for both methods and a difference in performance due to an internally optimized function to compute the Jacobian (as is provided by the CVODE library) is precluded.

In all of the computations conducted in this paper, we have used the infinity norm to scale v to its appropriate size. In general, we have found that the performance and accuracy of the computation is not significantly altered if the scaling is performed to some value that is reasonably close to [formula].

Conclusion

Using several examples of MHD problems, we have shown that exponential integrators constitute a viable alternative to the more commonly employed BDF method (as implemented in the CVODE library). In almost all instances equal or superior performance has been observed for the adaptive and variable time stepping fifth order EpiRK method for low to medium accuracy requirements.

Note that while the first version of the CVODE package was released several decades ago and the package has been optimized and refined over extended period of time, the EPIC package is the first C++/MPI implementation of the exponential integrators. As indicated in [\cite=loffeld14] there are a number of additional optimizations possible both from an algorithmic and from a computer science perspective. For example, significant performance gains are expected from improvements in the adaptivity algorithms in the Krylov projections and the derivation of the time integrators specifically adapted to a given system of equations. In addition, the newly introduced implicit-exponential (IMEXP) methods [\cite=rainwater2016] demonstrate that exponential integration can also be used as a component of the overall integration scheme and can be combined with the preconditioned implicit integrators as well as time splitting strategies. It is expected that further development will lead to significant performance improvements.

Furthermore, we note that the results presented here are somewhat different from the simpler models considered in [\citep=loffeld14]. In that case order of magnitude speedups are observed for the EpiRK method as compared to the CVODE implementation. Further investigations are needed to determine whether the degradation in comparative performance is due to the specifics of the PDE system, the details of the integrator or the particulars of the implementation. Also it is not clear to what degree the approximate computation of the Jacobian contributes to the observed differences (in all the problems investigated in [\citep=loffeld14] an analytical form of the Jacobian has been used).

Acknowledgements

We would like to take the opportunity to thank D. R. Reynolds for providing the code of the Fortran MHD solver and for the helpful discussion. Dr. Einkemmer was supported by the Marshall plan scholarship of the Austrian Marshall plan foundation (http://www.marshallplan.at/) and by the Fonds zur F�rderung der Wissenschaften (FWF) - project id: P25346. Dr. Tokman was supported by a grant from the National Science Foundation, Computational Mathematics Program, under Grant No. 1115978.

The simulations were conducted using the Vienna Scientific Cluster (VSC).